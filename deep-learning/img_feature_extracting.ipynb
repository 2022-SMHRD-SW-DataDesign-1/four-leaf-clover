{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b13fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import torch.utils.data as data\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as v_utils\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox, TextArea\n",
    "from matplotlib.cbook import get_sample_data\n",
    "from PIL import ImageFile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b779edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "image_size = 256\n",
    "PATH = \"./cropWebtoonImg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.ImageFolder(PATH,transform= transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        ]))\n",
    "\n",
    "print(data.class_to_idx)\n",
    "\n",
    "class_to_idx = data.class_to_idx\n",
    "idx_to_class = {}\n",
    "for key, value in enumerate(class_to_idx):\n",
    "    idx_to_class[key] = value\n",
    "    \n",
    "print(idx_to_class)\n",
    "\n",
    "img_list = []\n",
    "for i in data.imgs:\n",
    "    img_list.append(i[0])\n",
    "\n",
    "#img_list2 = []\n",
    "\n",
    "#for img in os.listdir('/content/drive/My Drive/dataset/thumnail'):\n",
    "#    img_list2.append(os.path.join('/content/drive/My Drive/dataset/thumnail',img))\n",
    "#img_list2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f9078c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet,self).__init__()\n",
    "        self.layer0 = nn.Sequential(*list(resnet.children())[0:1])\n",
    "        self.layer1 = nn.Sequential(*list(resnet.children())[1:4])\n",
    "        self.layer2 = nn.Sequential(*list(resnet.children())[4:5])\n",
    "        self.layer3 = nn.Sequential(*list(resnet.children())[5:6])\n",
    "        #self.layer4 = nn.Sequential(*list(resnet.children())[6:7])\n",
    "        #self.layer5 = nn.Sequential(*list(resnet.children())[7:8])\n",
    "\n",
    "    def forward(self,x):\n",
    "        out_0 = self.layer0(x)\n",
    "        out_1 = self.layer1(out_0)\n",
    "        out_2 = self.layer2(out_1)\n",
    "        out_3 = self.layer3(out_2)\n",
    "        #out_4 = self.layer4(out_3)\n",
    "        #out_5 = self.layer5(out_4)\n",
    "\n",
    "        return out_0, out_1, out_2, out_3, # out_4, out_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e025329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GramMatrix(nn.Module):\n",
    "    def forward(self, input):\n",
    "        b,c,h,w = input.size()\n",
    "        F = input.view(b, c, h*w)\n",
    "        G = torch.bmm(F, F.transpose(1,2)) \n",
    "        return G\n",
    "\n",
    "class GramMSELoss(nn.Module):\n",
    "    def forward(self, input, target):\n",
    "        out = nn.MSELoss()(GramMatrix()(input), target)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d22b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = Resnet().cuda()\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee6b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_arr = []\n",
    "label_arr = []\n",
    "\n",
    "for idx,(image,label) in enumerate(data):\n",
    "    i = image\n",
    "    i = i.view(-1,i.size()[0],i.size()[1],i.size()[2])\n",
    "\n",
    "    style_target = list(GramMatrix().cuda()(i) for i in resnet(i))\n",
    "\n",
    "    arr = torch.cat([style_target[0].view(-1),style_target[1].view(-1),style_target[2].view(-1),style_target[3].view(-1)],0)\n",
    "    gram = arr.cpu().data.numpy().reshape(1,-1)\n",
    "\n",
    "    total_arr.append(gram.reshape(-1))\n",
    "    label_arr.append(label)\n",
    "\n",
    "    if idx % 50 == 0 and idx != 0:\n",
    "        print(f'{idx} images style feature extracted..[{round(idx / len(data), 2) * 100}%]')\n",
    "print('Image style feature extraction done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09af60ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TSNE(n_components=2, init='pca',random_state=0, verbose=3, perplexity=100)\n",
    "result = model.fit_transform(total_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad8e1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[:2291][0].mean(), result[:2291][1].mean())\n",
    "print(label_arr[2291])\n",
    "print(result[2292:][0].mean(),result[2292:][1].mean())\n",
    "print(label_arr[2292])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc3fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imscatter(x, y, image, ax=None, zoom=1, show_by_thumnail=False, title='webtoon'):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    try:\n",
    "        image = plt.imread(image)\n",
    "    except TypeError:\n",
    "        # Likely already an array...\n",
    "        pass\n",
    "    im = OffsetImage(image, zoom=zoom)\n",
    "\n",
    "    # Convert inputs to arrays with at least one dimension.\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    \n",
    "    artists = []\n",
    "    for x0, y0 in zip(x, y):\n",
    "        ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=False)\n",
    "        \n",
    "\n",
    "        if show_by_thumnail:\n",
    "            offsetbox = TextArea(title, minimumdescent=False)\n",
    "            ac = AnnotationBbox(offsetbox, (x0, y0),\n",
    "                        xybox=(20, -40),\n",
    "                        xycoords='data',\n",
    "                        boxcoords=\"offset points\")\n",
    "            artists.append(ax.add_artist(ac))\n",
    "        artists.append(ax.add_artist(ab))\n",
    "\n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()\n",
    "    return artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e60d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(len(result)):\n",
    "    img_path = img_list[i]\n",
    "    imscatter(result[i,0],result[i,1], image=img_path, zoom=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e7ca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_list = []\n",
    "scatter_x = result[:, 0]\n",
    "scatter_y = result[:, 1]\n",
    "group = np.array(label_arr)\n",
    "\n",
    "for g in np.unique(group):\n",
    "    i = np.where(group==g)\n",
    "    x_avg = np.mean(scatter_x[i])\n",
    "    y_avg = np.mean(scatter_y[i])\n",
    "    avg_list.append((x_avg, y_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7be1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(len(avg_list)):\n",
    "    img_path = img_list2[i]\n",
    "    imscatter(avg_list[i][0],avg_list[i][1], image=img_path,zoom=0.6, show_by_thumnail=True, title=idx_to_class[i])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
