{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import torch.utils.data as data\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as v_utils\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "# from tsnecuda import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox, TextArea\n",
    "from matplotlib.cbook import get_sample_data\n",
    "from PIL import ImageFile\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "# import cupy as cp\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import gc\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "image_size = 256\n",
    "PATH = \"D:CropWebtoons/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'108명의 그녀들': 0, '1331': 1, '1초': 2, '1학년 9반': 3, '35cm': 4, '66666년 만에 환생한 흑마법사': 5, '6월의 라벤더': 6, '7FATES_ CHAKHO': 7, '99강화나무몽둥이': 8, 'AI 유하': 9, 'A_I_ 닥터': 10, 'DARK MOON_ 달의 제단': 11, 'DARK MOON_ 회색 도시': 12, 'THE 런웨이': 13, '가비지타임': 14, '가족같은 XX': 15, '가짜 동맹': 16, '간 떨어지는 출근': 17, '간첩 18세': 18, '강남의 기사': 19, '개를 낳았다': 20, '개와 사람의 시간': 21, '거래하실래요_': 22, '게임 최강 트롤러': 23, '겨울 정원의 하와르': 24, '겨울특강': 25, '격기3반': 26, '견우와 선녀': 27, '결혼공략': 28, '결혼까지 망상했어_': 29, '결혼생활 그림일기': 30, '경비실에서 안내방송 드립니다': 31, '경자 전성시대': 32, '고교흥신소': 33, '고백 취소도 되나_': 34, '고삼무쌍': 35, '고양이 타타': 36, '공유몽': 37, '광해의 연인': 38, '괴물공작의 딸': 39, '교환학생': 40, '국세청 망나니': 41, '굿바이 유교보이': 42, '굿헌팅': 43, '권리행사자': 44, '궤도의 아이들': 45, '궤짝': 46, '규격 외 혈통 천재': 47, '그 남자의 은밀한 하루': 48, '그 남주와 이별하는 방법': 49, '그 황제가 시곗바늘을 되돌린 사연': 50, '그냥 선생님': 51, '그녀석 정복기': 52, '그렇고 그런 바람에': 53, '그림자 잡기': 54, '그림자의 밤': 55, '급식러너': 56, '급식아빠': 57, '기억해줘': 58, '김부장': 59, '꼬리잡기': 60, '꽃만 키우는데 너무강함': 61, '꿈의 기업': 62, '나 혼자 네크로맨서': 63, '나 혼자 만렙 뉴비': 64, '나 혼자 특성빨로 무한 성장': 65, '나노마신': 66, '나랑X할래_': 67, '나를 바꿔줘': 68, '나만의 고막남친': 69, '나쁜 마법사의 꿈': 70, '나쁜사람': 71, '나의 계절': 72, '나의 불편한 상사': 73, '나의 작은 서점': 74, '나이트런': 75, '나타나주세요_': 76, '나태 공자_ 노력 천재 되다': 77, '낙원의 이론': 78, '낙향문사전': 79, '남편 먹는 여자': 80, '남편을 만렙으로 키우려 합니다': 81, '내 남편과 결혼해줘': 82, '내가 죽기로 결심한 것은': 83, '내가 키운 S급들': 84, '내게 필요한 NO맨스': 85, '내겐 너무 소란한 결혼': 86, '내곁엔 없을까': 87, '내남친 킹카만들기': 88, '내일': 89, '너를 돌려차는 방법': 90, '너에게 입덕중': 91, '너의 미소가 함정': 92, '너의 순정_ 나의 순정': 93, '너의 키스씬': 94, '널 사랑하는 죽은 형': 95, '네 것이었던 것': 96, '네가 죽기를 바랄 때가 있었다': 97, '넷시의 비밀': 98, '노답소녀': 99, '노량진 공격대': 100, '노빠꾸 최하영': 101, '놓지마 정신줄 시즌3': 102, '누나_ 나 무서워': 103, '늑대처럼 홀로': 104, '다비_ 아찔하게 흐르는': 105, '다시쓰는 연애사': 106, '달의 요람': 107, '달이 사라진 밤': 108, '달이 없는 나라': 109, '대공님_ 실수였어요_': 110, '대신 심부름을 해다오': 111, '대위님_ 이번 전쟁터는 이곳인가요_': 112, '대충 캠퍼스로맨스임': 113, '대학원 탈출일지': 114, '더 게이머': 115, '더 해머': 116, '더블클릭': 117, '던전 씹어먹는 아티팩트': 118, '데드퀸': 119, '데빌샷': 120, '덴큐': 121, '도깨비 부른다': 122, '도사 가온': 123, '도전_ 집콕취미': 124, '독거미': 125, '돌&아이': 126, '돌아온 여기사': 127, '두 번 사는 프로듀서': 128, '두 번째 딸로 태어났습니다': 129, '드래곤의 심장을 가지고 있습니다': 130, '디나운스': 131, '디펜스 게임의 폭군이 되었다': 132, '따개비': 133, '또 다른 사랑': 134, '또다시_ 계약 부부': 135, '똑 닮은 딸': 136, '뜨거운 홍차': 137, '라서드': 138, '랜덤채팅의 그녀_': 139, '랭커': 140, '로또 황녀님': 141, '로맨스가 가능해_': 142, '로맨틱 태평수산': 143, '로어 올림푸스': 144, '로잘린 보가트': 145, '루루라라 우리네 인생': 146, '루크 비셸 따라잡기': 147, '리턴 투 플레이어': 148, '마녀와 용의 신혼일기': 149, '마녀의 심판은 꽃이 된다': 150, '마녀이야기': 151, '마도': 152, '마루는 강쥐': 153, '마른 가지에 바람처럼': 154, '마법사가 죽음을 맞이하는 방법': 155, '마법스크롤 상인 지오': 156, '마섹남 _ 마술하는 섹시한 남자': 157, '마왕까지 한 걸음': 158, '마왕의 고백': 159, '마침내 사랑이에요 마왕님_': 160, '만능잡캐': 161, '말년용사': 162, '망나니 소교주로 환생했다': 163, '매지컬 급식_암살법사': 164, '메리의 불타는 행복회로': 165, '메모리얼': 166, '메소드 연기법': 167, '메트로헌터': 168, '멜빈이 그들에게 남긴 것': 169, '멸망 이후의 세계': 170, '멸종위기종인간': 171, '모노마니아': 172, '모스크바의 여명': 173, '모어 라이프': 174, '몸이 바뀌는 사정': 175, '몽홀': 176, '뫼신 사냥꾼': 177, '묘령의 황자': 178, '무림서부': 179, '무사만리행': 180, '무서운게 딱좋아_': 181, '문제적 왕자님': 182, '물고기로 살아남기': 183, '물어보는 사이': 184, '물위의 우리': 185, '뮤즈 온 유명': 186, '미니어처 생활백서': 187, '미드우트': 188, '미래의 골동품 가게': 189, '미친 후작을 길들이고 말았다': 190, '민간인 통제구역 _ 일급기밀': 191, '밀실 마피아 게임': 192, '밀행': 193, '반귀': 194, '반드시 해피엔딩': 195, '반짝반짝 작은 눈': 196, '밤마다 남편이 바뀐다': 197, '밤을 깨우는 마법': 198, '방과후 레시피': 199, '배달의 신': 200, '배트맨_ 웨인 패밀리 어드벤처': 201, '백XX': 202, '백년게임': 203, '백설을 위하여': 204, '백호랑': 205, '버그이터': 206, '버려진 나의 최애를 위하여': 207, '범이올시다_': 208, '베니루 BAENIRU': 209, '베어케어': 210, '별빛 커튼콜': 211, '별을 삼킨 너에게': 212, '별을 쫓는 소년들': 213, '보고 있지_': 214, '보물과 괴물의 도시': 215, '보스였음': 216, '보스의 노골적 취향': 217, '복수를 위한 결혼동맹': 218, '부캐인생': 219, '북부 공작님을 유혹하겠습니다': 220, '분신으로 자동사냥': 221, '불청객': 222, '뷰티풀 군바리': 223, '브레이커 _ 이터널 포스': 224, '블러드 리벤저': 225, '비밀친구': 226, '비서 일탈': 227, '빅맨': 228, '빌드업': 229, '빌런투킬': 230, '사공은주': 231, '사기 친 공작님을 유혹해버렸다': 232, '사내고충처리반': 233, '사람은 고쳐 쓰는 게 아니야_': 234, '사랑의 헌옷수거함': 235, '사랑하는 여배우들': 236, '사막에 핀 달': 237, '사변괴담': 238, '사상최강': 239, '사서고생_': 240, '사신': 241, '사신소년': 242, '사이다걸': 243, '사표내고 이계에서 힐링합니다': 244, '사형소년': 245, '산의 시간': 246, '살아남은 로맨스': 247, '삼국지톡': 248, '상남자': 249, '생존고백': 250, '샤인 스타': 251, '서브 남주가 파업하면 생기는 일': 252, '서울시 천사주의': 253, '서울역 드루이드': 254, '선남친 후연애': 255, '선배는 나빠요_': 256, '선을 넘은 연애': 257, '성스러운 그대 이르시길': 258, '세기말 풋사과 보습학원': 259, '세라는 망돌': 260, '세레나': 261, '세번째 로망스': 262, '세상은 돈과 권력': 263, '소공녀 민트': 264, '소녀의 세계': 265, '소녀재판': 266, '소년 검사': 267, '소름일기': 268, '손 안의 안단테': 269, '솔트앤페퍼': 270, '수영만화일기': 271, '수요웹툰의 나강림': 272, '수희0_tngmlek0_': 273, '순수한 동거생활': 274, '순정말고 순종': 275, '순정빌런': 276, '슈퍼스타 천대리': 277, '스치면 인연 스며들면 사랑': 278, '스터디그룹': 279, '스토커의 하루': 280, '시선 끝 브로콜리': 281, '시에라': 282, '시월드가 내게 집착한다': 283, '시체기사 군터': 284, '시한부인 줄 알았어요_': 285, '신군': 286, '신의 최애캐': 287, '신이 담긴 아이': 288, '신화급 귀속 아이템을 손에 넣었다': 289, '실버 쥬얼': 290, '싸움독학': 291, '쌈빡': 292, '쓰레기는 쓰레기통에_': 293, '아가사': 294, '아마도': 295, '아마도_ 굿모닝': 296, '아빠같은 남자': 297, '아슈타르테': 298, '아이돌만 하고 싶었는데': 299, '아이즈': 300, '아인슈페너': 301, '아찔한 전남편': 302, '아침을 지나 밤으로': 303, '아카데미에 위장취업당했다': 304, '아포크리파': 305, '아홉수 우리들': 306, '악녀 18세 공략기': 307, '악당과 악당이 만나면': 308, '악마라고 불러다오': 309, '악몽의 형상': 310, '안녕_ 나의 수집': 311, '안미운 우리들': 312, '애구애구': 313, '애옹식당': 314, '애증화음': 315, '앵무살수': 316, '약빨이 신선함': 317, '약탈 신부': 318, '약한영웅': 319, '어글리후드': 320, '어느 백작 영애의 이중생활': 321, '어느날 갑자기 서울은': 322, '어떤소란': 323, '어쩌다보니 천생연분': 324, '언니_ 이번 생엔 내가 왕비야': 325, '언다잉': 326, '언덕 위의 제임스': 327, '에브리띵 이즈 파인': 328, '에이머': 329, '엑스애쉬': 330, '엔딩_ 바꿔보려합니다': 331, '여고생 드래곤': 332, '여름의 너에게': 333, '여신강림': 334, '여신님의 호랑이 공략법': 335, '여우애담': 336, '여우자매': 337, '여자를 사귀고 싶다': 338, '역대급 영지 설계사': 339, '역주행_': 340, '연놈': 341, '연애 연기대상': 342, '연애고수': 343, '연애의 기록': 344, '연애혁명': 345, '연우의 순정': 346, '열녀박씨 계약결혼뎐': 347, '영앤리치가 아니야_': 348, '영웅&마왕&악당': 349, '옆집남자 친구': 350, '오_ 친애하는 숙적': 351, '오늘의 비너스': 352, '오로지 오로라': 353, '오빠집이 비어서': 354, '오직_ 밝은 미래': 355, '온리호프': 356, '온새미로': 357, '온실 속 화초': 358, '올가미': 359, '완벽한 결혼의 정석': 360, '완벽한 부부는 없다': 361, '완벽한 파트너': 362, '왕게임': 363, '왕년엔 용사님': 364, '왕세자 입학도': 365, '외모지상주의': 366, '용두사망 소설 속의 악녀가 되었다': 367, '용사가 돌아왔다': 368, '용사참수인': 369, '용왕님의 셰프가 되었습니다': 370, '용한소녀': 371, '우리 무슨 사이야_': 372, '우리 은하': 373, '우산 없는 애': 374, '운명을 보는 회사원': 375, '웅크': 376, '원수가 나를 유혹할 때': 377, '원작은 완결난 지 한참 됐습니다만': 378, '원주민 공포만화': 379, '원하나': 380, '위닝샷_': 381, '위대한 겸상': 382, '위아더좀비': 383, '위험한 남편을 길들이는 법': 384, '윈드브레이커': 385, '윌유메리미': 386, '유사연애': 387, '유월의 소한': 388, '은둔코인': 389, '은주의 방 2_3부': 390, '은탄': 391, '이 결혼_ 새로고침': 392, '이 짝사랑은 억울하다_': 393, '이건 그냥 연애 이야기': 394, '이게 아닌데': 395, '이게 웬 떡': 396, '이계진입 리로디드': 397, '이러면 안 돼요_ 전하_': 398, '이런 미친 엔딩': 399, '이별 후 사내 결혼': 400, '이별학': 401, '이세계 용사가 지구를 구하는 이유': 402, '이십팔세기 광팬': 403, '이제야 연애': 404, '인과관계': 405, '인생영화': 406, '인섹터': 407, '인피니티': 408, '일렉시드': 409, '일타강사 백사부': 410, '입술이 예쁜 남자': 411, '입학용병': 412, '자매전쟁': 413, '자취방 신선들': 414, '작전명 순정': 415, '잔불의 기사': 416, '장미같은 소리': 417, '장씨세가 호위무사': 418, '장풍전': 419, '재벌집 막내아들': 420, '재생존경쟁': 421, '잿더미 황후': 422, '잿빛도 색이다': 423, '잿빛오름': 424, '저 그런 인재 아닙니다': 425, '저무는 해_ 시린 눈': 426, '적월의 나라': 427, '전남편의 미친개를 길들였다': 428, '전생연분': 429, '전지적 독자 시점': 430, '절대복종': 431, '제로게임': 432, '제왕_ 빛과 그림자': 433, '조선여우스캔들': 434, '존잘주의': 435, '좀간': 436, '주부 육성중': 437, '주인님을 잡아먹는 방법': 438, '주작연애': 439, '중독연구소': 440, '중매쟁이 아가 황녀님': 441, '지니오패스': 442, '지옥 키우기': 443, '지옥급식': 444, '지옥연애환담': 445, '집사_ 주세요_': 446, '집이 없어': 447, '짝사랑 마들렌': 448, '짝사랑의 마침표': 449, '찐_종합게임동아리': 450, '참교육': 451, '천년간 노려왔습니다': 452, '천마는 평범하게 살 수 없다': 453, '천마육성': 454, '천상의 주인': 455, '천재의 게임방송': 456, '천치전능': 457, '천하제일 대사형': 458, '천하제일인': 459, '천화서고 대공자': 460, '철수와 영희 이야기': 461, '첫날밤만 세 번째': 462, '청춘 블라썸': 463, '청춘계시록': 464, '청춘일지': 465, '초인의 게임': 466, '최강부캐': 467, '최강전설 강해효': 468, '최면학교': 469, '최후의 금빛아이': 470, '취사병 전설이 되다': 471, '카루나': 472, '칼끝에 입술': 473, '칼부림': 474, '칼에 취한 밤을 걷다': 475, '커플브레이커': 476, '코인 리벤지': 477, '쿠베라': 478, '쿠쿠쿠쿠': 479, '퀘스트지상주의': 480, '크림슨 하트': 481, '키미앤조이': 482, '키스 식스 센스': 483, '키스의 여왕': 484, '킬 더 드래곤': 485, '킬더킹': 486, '킬링킬러': 487, '탑코너': 488, '태권보이': 489, '퇴근 후에 만나요': 490, '튜토리얼 탑의 고인물': 491, '트롤트랩': 492, '특수청소': 493, '팀장님은 신혼이 피곤하다': 494, '파견체': 495, '파운더': 496, '판사 이한영': 497, '판타지 여동생_': 498, '팔이피플': 499, '패션쇼': 500, '팬인데 왜요': 501, '퍼니게임': 502, '평행도시': 503, '폭군 남편과 이혼하겠습니다': 504, '폭군님은 착하게 살고 싶어': 505, '폰투스 _ 극야2': 506, '푸른 밤_ 황홀의 윤무': 507, '푸쉬오프': 508, '풋내기들': 509, '프로듀스 온리원': 510, '프리드로우': 511, '플레이어': 512, '필리아로제 _ 가시왕관의 예언': 513, '필생기': 514, '하나는 적고 둘은 너무 많아': 515, '하렘에서 살아남기': 516, '하렘의 남자들': 517, '하루만 네가 되고 싶어': 518, '하루의 하루': 519, '하북팽가 막내아들': 520, '하얀 사자의 비밀 신부': 521, '한림체육관': 522, '한입만_': 523, '합격시켜주세용': 524, '합법해적 파르페': 525, '햄버거가 제일 좋아': 526, '행성인간2_ 행성의': 527, '행운을 부탁해_': 528, '행운을 빌어요_ 용사님_': 529, '헤어지면 죽음': 530, '헥토파스칼': 531, '헬스던전': 532, '헬크래프트': 533, '현실퀘스트': 534, '호랑신랑뎐': 535, '호랑이 들어와요': 536, '호랑이형님': 537, '홀리데이': 538, '홍 의관의 은밀한 비밀': 539, '홍시는 날 좋아해_': 540, '환상연가': 541, '황궁에 핀 꽃은_ 미쳤다': 542, '황제사냥': 543, '황제와의 하룻밤': 544, '회귀한 천재 헌터의 슬기로운 청소생활': 545, '후궁 스캔들': 546, '후덜덜덜 남극전자': 547, '흑막 여주가 날 새엄마로 만들려고 해': 548, '히어로 더 맥시멈': 549, '히어로 킬러': 550, '히어로메이커': 551}\n",
      "{0: '108명의 그녀들', 1: '1331', 2: '1초', 3: '1학년 9반', 4: '35cm', 5: '66666년 만에 환생한 흑마법사', 6: '6월의 라벤더', 7: '7FATES_ CHAKHO', 8: '99강화나무몽둥이', 9: 'AI 유하', 10: 'A_I_ 닥터', 11: 'DARK MOON_ 달의 제단', 12: 'DARK MOON_ 회색 도시', 13: 'THE 런웨이', 14: '가비지타임', 15: '가족같은 XX', 16: '가짜 동맹', 17: '간 떨어지는 출근', 18: '간첩 18세', 19: '강남의 기사', 20: '개를 낳았다', 21: '개와 사람의 시간', 22: '거래하실래요_', 23: '게임 최강 트롤러', 24: '겨울 정원의 하와르', 25: '겨울특강', 26: '격기3반', 27: '견우와 선녀', 28: '결혼공략', 29: '결혼까지 망상했어_', 30: '결혼생활 그림일기', 31: '경비실에서 안내방송 드립니다', 32: '경자 전성시대', 33: '고교흥신소', 34: '고백 취소도 되나_', 35: '고삼무쌍', 36: '고양이 타타', 37: '공유몽', 38: '광해의 연인', 39: '괴물공작의 딸', 40: '교환학생', 41: '국세청 망나니', 42: '굿바이 유교보이', 43: '굿헌팅', 44: '권리행사자', 45: '궤도의 아이들', 46: '궤짝', 47: '규격 외 혈통 천재', 48: '그 남자의 은밀한 하루', 49: '그 남주와 이별하는 방법', 50: '그 황제가 시곗바늘을 되돌린 사연', 51: '그냥 선생님', 52: '그녀석 정복기', 53: '그렇고 그런 바람에', 54: '그림자 잡기', 55: '그림자의 밤', 56: '급식러너', 57: '급식아빠', 58: '기억해줘', 59: '김부장', 60: '꼬리잡기', 61: '꽃만 키우는데 너무강함', 62: '꿈의 기업', 63: '나 혼자 네크로맨서', 64: '나 혼자 만렙 뉴비', 65: '나 혼자 특성빨로 무한 성장', 66: '나노마신', 67: '나랑X할래_', 68: '나를 바꿔줘', 69: '나만의 고막남친', 70: '나쁜 마법사의 꿈', 71: '나쁜사람', 72: '나의 계절', 73: '나의 불편한 상사', 74: '나의 작은 서점', 75: '나이트런', 76: '나타나주세요_', 77: '나태 공자_ 노력 천재 되다', 78: '낙원의 이론', 79: '낙향문사전', 80: '남편 먹는 여자', 81: '남편을 만렙으로 키우려 합니다', 82: '내 남편과 결혼해줘', 83: '내가 죽기로 결심한 것은', 84: '내가 키운 S급들', 85: '내게 필요한 NO맨스', 86: '내겐 너무 소란한 결혼', 87: '내곁엔 없을까', 88: '내남친 킹카만들기', 89: '내일', 90: '너를 돌려차는 방법', 91: '너에게 입덕중', 92: '너의 미소가 함정', 93: '너의 순정_ 나의 순정', 94: '너의 키스씬', 95: '널 사랑하는 죽은 형', 96: '네 것이었던 것', 97: '네가 죽기를 바랄 때가 있었다', 98: '넷시의 비밀', 99: '노답소녀', 100: '노량진 공격대', 101: '노빠꾸 최하영', 102: '놓지마 정신줄 시즌3', 103: '누나_ 나 무서워', 104: '늑대처럼 홀로', 105: '다비_ 아찔하게 흐르는', 106: '다시쓰는 연애사', 107: '달의 요람', 108: '달이 사라진 밤', 109: '달이 없는 나라', 110: '대공님_ 실수였어요_', 111: '대신 심부름을 해다오', 112: '대위님_ 이번 전쟁터는 이곳인가요_', 113: '대충 캠퍼스로맨스임', 114: '대학원 탈출일지', 115: '더 게이머', 116: '더 해머', 117: '더블클릭', 118: '던전 씹어먹는 아티팩트', 119: '데드퀸', 120: '데빌샷', 121: '덴큐', 122: '도깨비 부른다', 123: '도사 가온', 124: '도전_ 집콕취미', 125: '독거미', 126: '돌&아이', 127: '돌아온 여기사', 128: '두 번 사는 프로듀서', 129: '두 번째 딸로 태어났습니다', 130: '드래곤의 심장을 가지고 있습니다', 131: '디나운스', 132: '디펜스 게임의 폭군이 되었다', 133: '따개비', 134: '또 다른 사랑', 135: '또다시_ 계약 부부', 136: '똑 닮은 딸', 137: '뜨거운 홍차', 138: '라서드', 139: '랜덤채팅의 그녀_', 140: '랭커', 141: '로또 황녀님', 142: '로맨스가 가능해_', 143: '로맨틱 태평수산', 144: '로어 올림푸스', 145: '로잘린 보가트', 146: '루루라라 우리네 인생', 147: '루크 비셸 따라잡기', 148: '리턴 투 플레이어', 149: '마녀와 용의 신혼일기', 150: '마녀의 심판은 꽃이 된다', 151: '마녀이야기', 152: '마도', 153: '마루는 강쥐', 154: '마른 가지에 바람처럼', 155: '마법사가 죽음을 맞이하는 방법', 156: '마법스크롤 상인 지오', 157: '마섹남 _ 마술하는 섹시한 남자', 158: '마왕까지 한 걸음', 159: '마왕의 고백', 160: '마침내 사랑이에요 마왕님_', 161: '만능잡캐', 162: '말년용사', 163: '망나니 소교주로 환생했다', 164: '매지컬 급식_암살법사', 165: '메리의 불타는 행복회로', 166: '메모리얼', 167: '메소드 연기법', 168: '메트로헌터', 169: '멜빈이 그들에게 남긴 것', 170: '멸망 이후의 세계', 171: '멸종위기종인간', 172: '모노마니아', 173: '모스크바의 여명', 174: '모어 라이프', 175: '몸이 바뀌는 사정', 176: '몽홀', 177: '뫼신 사냥꾼', 178: '묘령의 황자', 179: '무림서부', 180: '무사만리행', 181: '무서운게 딱좋아_', 182: '문제적 왕자님', 183: '물고기로 살아남기', 184: '물어보는 사이', 185: '물위의 우리', 186: '뮤즈 온 유명', 187: '미니어처 생활백서', 188: '미드우트', 189: '미래의 골동품 가게', 190: '미친 후작을 길들이고 말았다', 191: '민간인 통제구역 _ 일급기밀', 192: '밀실 마피아 게임', 193: '밀행', 194: '반귀', 195: '반드시 해피엔딩', 196: '반짝반짝 작은 눈', 197: '밤마다 남편이 바뀐다', 198: '밤을 깨우는 마법', 199: '방과후 레시피', 200: '배달의 신', 201: '배트맨_ 웨인 패밀리 어드벤처', 202: '백XX', 203: '백년게임', 204: '백설을 위하여', 205: '백호랑', 206: '버그이터', 207: '버려진 나의 최애를 위하여', 208: '범이올시다_', 209: '베니루 BAENIRU', 210: '베어케어', 211: '별빛 커튼콜', 212: '별을 삼킨 너에게', 213: '별을 쫓는 소년들', 214: '보고 있지_', 215: '보물과 괴물의 도시', 216: '보스였음', 217: '보스의 노골적 취향', 218: '복수를 위한 결혼동맹', 219: '부캐인생', 220: '북부 공작님을 유혹하겠습니다', 221: '분신으로 자동사냥', 222: '불청객', 223: '뷰티풀 군바리', 224: '브레이커 _ 이터널 포스', 225: '블러드 리벤저', 226: '비밀친구', 227: '비서 일탈', 228: '빅맨', 229: '빌드업', 230: '빌런투킬', 231: '사공은주', 232: '사기 친 공작님을 유혹해버렸다', 233: '사내고충처리반', 234: '사람은 고쳐 쓰는 게 아니야_', 235: '사랑의 헌옷수거함', 236: '사랑하는 여배우들', 237: '사막에 핀 달', 238: '사변괴담', 239: '사상최강', 240: '사서고생_', 241: '사신', 242: '사신소년', 243: '사이다걸', 244: '사표내고 이계에서 힐링합니다', 245: '사형소년', 246: '산의 시간', 247: '살아남은 로맨스', 248: '삼국지톡', 249: '상남자', 250: '생존고백', 251: '샤인 스타', 252: '서브 남주가 파업하면 생기는 일', 253: '서울시 천사주의', 254: '서울역 드루이드', 255: '선남친 후연애', 256: '선배는 나빠요_', 257: '선을 넘은 연애', 258: '성스러운 그대 이르시길', 259: '세기말 풋사과 보습학원', 260: '세라는 망돌', 261: '세레나', 262: '세번째 로망스', 263: '세상은 돈과 권력', 264: '소공녀 민트', 265: '소녀의 세계', 266: '소녀재판', 267: '소년 검사', 268: '소름일기', 269: '손 안의 안단테', 270: '솔트앤페퍼', 271: '수영만화일기', 272: '수요웹툰의 나강림', 273: '수희0_tngmlek0_', 274: '순수한 동거생활', 275: '순정말고 순종', 276: '순정빌런', 277: '슈퍼스타 천대리', 278: '스치면 인연 스며들면 사랑', 279: '스터디그룹', 280: '스토커의 하루', 281: '시선 끝 브로콜리', 282: '시에라', 283: '시월드가 내게 집착한다', 284: '시체기사 군터', 285: '시한부인 줄 알았어요_', 286: '신군', 287: '신의 최애캐', 288: '신이 담긴 아이', 289: '신화급 귀속 아이템을 손에 넣었다', 290: '실버 쥬얼', 291: '싸움독학', 292: '쌈빡', 293: '쓰레기는 쓰레기통에_', 294: '아가사', 295: '아마도', 296: '아마도_ 굿모닝', 297: '아빠같은 남자', 298: '아슈타르테', 299: '아이돌만 하고 싶었는데', 300: '아이즈', 301: '아인슈페너', 302: '아찔한 전남편', 303: '아침을 지나 밤으로', 304: '아카데미에 위장취업당했다', 305: '아포크리파', 306: '아홉수 우리들', 307: '악녀 18세 공략기', 308: '악당과 악당이 만나면', 309: '악마라고 불러다오', 310: '악몽의 형상', 311: '안녕_ 나의 수집', 312: '안미운 우리들', 313: '애구애구', 314: '애옹식당', 315: '애증화음', 316: '앵무살수', 317: '약빨이 신선함', 318: '약탈 신부', 319: '약한영웅', 320: '어글리후드', 321: '어느 백작 영애의 이중생활', 322: '어느날 갑자기 서울은', 323: '어떤소란', 324: '어쩌다보니 천생연분', 325: '언니_ 이번 생엔 내가 왕비야', 326: '언다잉', 327: '언덕 위의 제임스', 328: '에브리띵 이즈 파인', 329: '에이머', 330: '엑스애쉬', 331: '엔딩_ 바꿔보려합니다', 332: '여고생 드래곤', 333: '여름의 너에게', 334: '여신강림', 335: '여신님의 호랑이 공략법', 336: '여우애담', 337: '여우자매', 338: '여자를 사귀고 싶다', 339: '역대급 영지 설계사', 340: '역주행_', 341: '연놈', 342: '연애 연기대상', 343: '연애고수', 344: '연애의 기록', 345: '연애혁명', 346: '연우의 순정', 347: '열녀박씨 계약결혼뎐', 348: '영앤리치가 아니야_', 349: '영웅&마왕&악당', 350: '옆집남자 친구', 351: '오_ 친애하는 숙적', 352: '오늘의 비너스', 353: '오로지 오로라', 354: '오빠집이 비어서', 355: '오직_ 밝은 미래', 356: '온리호프', 357: '온새미로', 358: '온실 속 화초', 359: '올가미', 360: '완벽한 결혼의 정석', 361: '완벽한 부부는 없다', 362: '완벽한 파트너', 363: '왕게임', 364: '왕년엔 용사님', 365: '왕세자 입학도', 366: '외모지상주의', 367: '용두사망 소설 속의 악녀가 되었다', 368: '용사가 돌아왔다', 369: '용사참수인', 370: '용왕님의 셰프가 되었습니다', 371: '용한소녀', 372: '우리 무슨 사이야_', 373: '우리 은하', 374: '우산 없는 애', 375: '운명을 보는 회사원', 376: '웅크', 377: '원수가 나를 유혹할 때', 378: '원작은 완결난 지 한참 됐습니다만', 379: '원주민 공포만화', 380: '원하나', 381: '위닝샷_', 382: '위대한 겸상', 383: '위아더좀비', 384: '위험한 남편을 길들이는 법', 385: '윈드브레이커', 386: '윌유메리미', 387: '유사연애', 388: '유월의 소한', 389: '은둔코인', 390: '은주의 방 2_3부', 391: '은탄', 392: '이 결혼_ 새로고침', 393: '이 짝사랑은 억울하다_', 394: '이건 그냥 연애 이야기', 395: '이게 아닌데', 396: '이게 웬 떡', 397: '이계진입 리로디드', 398: '이러면 안 돼요_ 전하_', 399: '이런 미친 엔딩', 400: '이별 후 사내 결혼', 401: '이별학', 402: '이세계 용사가 지구를 구하는 이유', 403: '이십팔세기 광팬', 404: '이제야 연애', 405: '인과관계', 406: '인생영화', 407: '인섹터', 408: '인피니티', 409: '일렉시드', 410: '일타강사 백사부', 411: '입술이 예쁜 남자', 412: '입학용병', 413: '자매전쟁', 414: '자취방 신선들', 415: '작전명 순정', 416: '잔불의 기사', 417: '장미같은 소리', 418: '장씨세가 호위무사', 419: '장풍전', 420: '재벌집 막내아들', 421: '재생존경쟁', 422: '잿더미 황후', 423: '잿빛도 색이다', 424: '잿빛오름', 425: '저 그런 인재 아닙니다', 426: '저무는 해_ 시린 눈', 427: '적월의 나라', 428: '전남편의 미친개를 길들였다', 429: '전생연분', 430: '전지적 독자 시점', 431: '절대복종', 432: '제로게임', 433: '제왕_ 빛과 그림자', 434: '조선여우스캔들', 435: '존잘주의', 436: '좀간', 437: '주부 육성중', 438: '주인님을 잡아먹는 방법', 439: '주작연애', 440: '중독연구소', 441: '중매쟁이 아가 황녀님', 442: '지니오패스', 443: '지옥 키우기', 444: '지옥급식', 445: '지옥연애환담', 446: '집사_ 주세요_', 447: '집이 없어', 448: '짝사랑 마들렌', 449: '짝사랑의 마침표', 450: '찐_종합게임동아리', 451: '참교육', 452: '천년간 노려왔습니다', 453: '천마는 평범하게 살 수 없다', 454: '천마육성', 455: '천상의 주인', 456: '천재의 게임방송', 457: '천치전능', 458: '천하제일 대사형', 459: '천하제일인', 460: '천화서고 대공자', 461: '철수와 영희 이야기', 462: '첫날밤만 세 번째', 463: '청춘 블라썸', 464: '청춘계시록', 465: '청춘일지', 466: '초인의 게임', 467: '최강부캐', 468: '최강전설 강해효', 469: '최면학교', 470: '최후의 금빛아이', 471: '취사병 전설이 되다', 472: '카루나', 473: '칼끝에 입술', 474: '칼부림', 475: '칼에 취한 밤을 걷다', 476: '커플브레이커', 477: '코인 리벤지', 478: '쿠베라', 479: '쿠쿠쿠쿠', 480: '퀘스트지상주의', 481: '크림슨 하트', 482: '키미앤조이', 483: '키스 식스 센스', 484: '키스의 여왕', 485: '킬 더 드래곤', 486: '킬더킹', 487: '킬링킬러', 488: '탑코너', 489: '태권보이', 490: '퇴근 후에 만나요', 491: '튜토리얼 탑의 고인물', 492: '트롤트랩', 493: '특수청소', 494: '팀장님은 신혼이 피곤하다', 495: '파견체', 496: '파운더', 497: '판사 이한영', 498: '판타지 여동생_', 499: '팔이피플', 500: '패션쇼', 501: '팬인데 왜요', 502: '퍼니게임', 503: '평행도시', 504: '폭군 남편과 이혼하겠습니다', 505: '폭군님은 착하게 살고 싶어', 506: '폰투스 _ 극야2', 507: '푸른 밤_ 황홀의 윤무', 508: '푸쉬오프', 509: '풋내기들', 510: '프로듀스 온리원', 511: '프리드로우', 512: '플레이어', 513: '필리아로제 _ 가시왕관의 예언', 514: '필생기', 515: '하나는 적고 둘은 너무 많아', 516: '하렘에서 살아남기', 517: '하렘의 남자들', 518: '하루만 네가 되고 싶어', 519: '하루의 하루', 520: '하북팽가 막내아들', 521: '하얀 사자의 비밀 신부', 522: '한림체육관', 523: '한입만_', 524: '합격시켜주세용', 525: '합법해적 파르페', 526: '햄버거가 제일 좋아', 527: '행성인간2_ 행성의', 528: '행운을 부탁해_', 529: '행운을 빌어요_ 용사님_', 530: '헤어지면 죽음', 531: '헥토파스칼', 532: '헬스던전', 533: '헬크래프트', 534: '현실퀘스트', 535: '호랑신랑뎐', 536: '호랑이 들어와요', 537: '호랑이형님', 538: '홀리데이', 539: '홍 의관의 은밀한 비밀', 540: '홍시는 날 좋아해_', 541: '환상연가', 542: '황궁에 핀 꽃은_ 미쳤다', 543: '황제사냥', 544: '황제와의 하룻밤', 545: '회귀한 천재 헌터의 슬기로운 청소생활', 546: '후궁 스캔들', 547: '후덜덜덜 남극전자', 548: '흑막 여주가 날 새엄마로 만들려고 해', 549: '히어로 더 맥시멈', 550: '히어로 킬러', 551: '히어로메이커'}\n"
     ]
    }
   ],
   "source": [
    "data = datasets.ImageFolder(PATH,transform= transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "        transforms.Grayscale(num_output_channels=3)\n",
    "        ]))\n",
    "\n",
    "print(data.class_to_idx)\n",
    "\n",
    "class_to_idx = data.class_to_idx\n",
    "idx_to_class = {}\n",
    "for key, value in enumerate(class_to_idx):\n",
    "    idx_to_class[key] = value\n",
    "    \n",
    "print(idx_to_class)\n",
    "# all_file_idx_to_class = idx_to_class\n",
    "# img_list = []\n",
    "# for i in data.imgs:\n",
    "#     img_list.append(i[0])\n",
    "\n",
    "#img_list2 = []\n",
    "\n",
    "#for img in os.listdir('/content/drive/My Drive/dataset/thumnail'):\n",
    "#    img_list2.append(os.path.join('/content/drive/My Drive/dataset/thumnail',img))\n",
    "#img_list2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_idx_to_class = {0: '108명의 그녀들', 1: '1331', 2: '1초', 3: '1학년 9반', 4: '35cm', 5: '66666년 만에 환생한 흑마법사', 6: '6월의 라벤더', 7: '7FATES_ CHAKHO', 8: '99강화나무몽둥이', 9: 'AI 유하', 10: 'A_I_ 닥터', 11: 'DARK MOON_ 달의 제단', 12: 'DARK MOON_ 회색 도시', 13: 'THE 런웨이', 14: '가비지타임', 15: '가족같은 XX', 16: '가짜 동맹', 17: '간 떨어지는 출근', 18: '간첩 18세', 19: '강남의 기사', 20: '개를 낳았다', 21: '개와 사람의 시간', 22: '거래하실래요_', 23: '게임 최강 트롤러', 24: '겨울 정원의 하와르', 25: '겨울특강', 26: '격기3반', 27: '견우와 선녀', 28: '결혼공략', 29: '결혼까지 망상했어_', 30: '결혼생활 그림일기', 31: '경비실에서 안내방송 드립니다', 32: '경자 전성시대', 33: '고교흥신소', 34: '고백 취소도 되나_', 35: '고삼무쌍', 36: '고양이 타타', 37: '공유몽', 38: '광해의 연인', 39: '괴물공작의 딸', 40: '교환학생', 41: '국세청 망나니', 42: '굿바이 유교보이', 43: '굿헌팅', 44: '권리행사자', 45: '궤도의 아이들', 46: '궤짝', 47: '규격 외 혈통 천재', 48: '그 남자의 은밀한 하루', 49: '그 남주와 이별하는 방법', 50: '그 황제가 시곗바늘을 되돌린 사연', 51: '그냥 선생님', 52: '그녀석 정복기', 53: '그렇고 그런 바람에', 54: '그림자 잡기', 55: '그림자의 밤', 56: '급식러너', 57: '급식아빠', 58: '기억해줘', 59: '김부장', 60: '꼬리잡기', 61: '꽃만 키우는데 너무강함', 62: '꿈의 기업', 63: '나 혼자 네크로맨서', 64: '나 혼자 만렙 뉴비', 65: '나 혼자 특성빨로 무한 성장', 66: '나노마신', 67: '나랑X할래_', 68: '나를 바꿔줘', 69: '나만의 고막남친', 70: '나쁜 마법사의 꿈', 71: '나쁜사람', 72: '나의 계절', 73: '나의 불편한 상사', 74: '나의 작은 서점', 75: '나이트런', 76: '나타나주세요_', 77: '나태 공자_ 노력 천재 되다', 78: '낙원의 이론', 79: '낙향문사전', 80: '남편 먹는 여자', 81: '남편을 만렙으로 키우려 합니다', 82: '내 남편과 결혼해줘', 83: '내가 죽기로 결심한 것은', 84: '내가 키운 S급들', 85: '내게 필요한 NO맨스', 86: '내겐 너무 소란한 결혼', 87: '내곁엔 없을까', 88: '내남친 킹카만들기', 89: '내일', 90: '너를 돌려차는 방법', 91: '너에게 입덕중', 92: '너의 미소가 함정', 93: '너의 순정_ 나의 순정', 94: '너의 키스씬', 95: '널 사랑하는 죽은 형', 96: '네 것이었던 것', 97: '네가 죽기를 바랄 때가 있었다', 98: '넷시의 비밀', 99: '노답소녀', 100: '노량진 공격대', 101: '노빠꾸 최하영', 102: '놓지마 정신줄 시즌3', 103: '누나_ 나 무서워', 104: '늑대처럼 홀로', 105: '다비_ 아찔하게 흐르는', 106: '다시쓰는 연애사', 107: '달의 요람', 108: '달이 사라진 밤', 109: '달이 없는 나라', 110: '대공님_ 실수였어요_', 111: '대신 심부름을 해다오', 112: '대위님_ 이번 전쟁터는 이곳인가요_', 113: '대충 캠퍼스로맨스임', 114: '대학원 탈출일지', 115: '더 게이머', 116: '더 해머', 117: '더블클릭', 118: '던전 씹어먹는 아티팩트', 119: '데드퀸', 120: '데빌샷', 121: '덴큐', 122: '도깨비 부른다', 123: '도사 가온', 124: '도전_ 집콕취미', 125: '독거미', 126: '돌&아이', 127: '돌아온 여기사', 128: '두 번 사는 프로듀서', 129: '두 번째 딸로 태어났습니다', 130: '드래곤의 심장을 가지고 있습니다', 131: '디나운스', 132: '디펜스 게임의 폭군이 되었다', 133: '따개비', 134: '또 다른 사랑', 135: '또다시_ 계약 부부', 136: '똑 닮은 딸', 137: '뜨거운 홍차', 138: '라서드', 139: '랜덤채팅의 그녀_', 140: '랭커', 141: '로또 황녀님', 142: '로맨스가 가능해_', 143: '로맨틱 태평수산', 144: '로어 올림푸스', 145: '로잘린 보가트', 146: '루루라라 우리네 인생', 147: '루크 비셸 따라잡기', 148: '리턴 투 플레이어', 149: '마녀와 용의 신혼일기', 150: '마녀의 심판은 꽃이 된다', 151: '마녀이야기', 152: '마도', 153: '마루는 강쥐', 154: '마른 가지에 바람처럼', 155: '마법사가 죽음을 맞이하는 방법', 156: '마법스크롤 상인 지오', 157: '마섹남 _ 마술하는 섹시한 남자', 158: '마왕까지 한 걸음', 159: '마왕의 고백', 160: '마침내 사랑이에요 마왕님_', 161: '만능잡캐', 162: '말년용사', 163: '망나니 소교주로 환생했다', 164: '매지컬 급식_암살법사', 165: '메리의 불타는 행복회로', 166: '메모리얼', 167: '메소드 연기법', 168: '메트로헌터', 169: '멜빈이 그들에게 남긴 것', 170: '멸망 이후의 세계', 171: '멸종위기종인간', 172: '모노마니아', 173: '모스크바의 여명', 174: '모어 라이프', 175: '몸이 바뀌는 사정', 176: '몽홀', 177: '뫼신 사냥꾼', 178: '묘령의 황자', 179: '무림서부', 180: '무사만리행', 181: '무서운게 딱좋아_', 182: '문제적 왕자님', 183: '물고기로 살아남기', 184: '물어보는 사이', 185: '물위의 우리', 186: '뮤즈 온 유명', 187: '미니어처 생활백서', 188: '미드우트', 189: '미래의 골동품 가게', 190: '미친 후작을 길들이고 말았다', 191: '민간인 통제구역 _ 일급기밀', 192: '밀실 마피아 게임', 193: '밀행', 194: '반귀', 195: '반드시 해피엔딩', 196: '반짝반짝 작은 눈', 197: '밤마다 남편이 바뀐다', 198: '밤을 깨우는 마법', 199: '방과후 레시피', 200: '배달의 신', 201: '배트맨_ 웨인 패밀리 어드벤처', 202: '백XX', 203: '백년게임', 204: '백설을 위하여', 205: '백호랑', 206: '버그이터', 207: '버려진 나의 최애를 위하여', 208: '범이올시다_', 209: '베니루 BAENIRU', 210: '베어케어', 211: '별빛 커튼콜', 212: '별을 삼킨 너에게', 213: '별을 쫓는 소년들', 214: '보고 있지_', 215: '보물과 괴물의 도시', 216: '보스였음', 217: '보스의 노골적 취향', 218: '복수를 위한 결혼동맹', 219: '부캐인생', 220: '북부 공작님을 유혹하겠습니다', 221: '분신으로 자동사냥', 222: '불청객', 223: '뷰티풀 군바리', 224: '브레이커 _ 이터널 포스', 225: '블러드 리벤저', 226: '비밀친구', 227: '비서 일탈', 228: '빅맨', 229: '빌드업', 230: '빌런투킬', 231: '사공은주', 232: '사기 친 공작님을 유혹해버렸다', 233: '사내고충처리반', 234: '사람은 고쳐 쓰는 게 아니야_', 235: '사랑의 헌옷수거함', 236: '사랑하는 여배우들', 237: '사막에 핀 달', 238: '사변괴담', 239: '사상최강', 240: '사서고생_', 241: '사신', 242: '사신소년', 243: '사이다걸', 244: '사표내고 이계에서 힐링합니다', 245: '사형소년', 246: '산의 시간', 247: '살아남은 로맨스', 248: '삼국지톡', 249: '상남자', 250: '생존고백', 251: '샤인 스타', 252: '서브 남주가 파업하면 생기는 일', 253: '서울시 천사주의', 254: '서울역 드루이드', 255: '선남친 후연애', 256: '선배는 나빠요_', 257: '선을 넘은 연애', 258: '성스러운 그대 이르시길', 259: '세기말 풋사과 보습학원', 260: '세라는 망돌', 261: '세레나', 262: '세번째 로망스', 263: '세상은 돈과 권력', 264: '소공녀 민트', 265: '소녀의 세계', 266: '소녀재판', 267: '소년 검사', 268: '소름일기', 269: '손 안의 안단테', 270: '솔트앤페퍼', 271: '수영만화일기', 272: '수요웹툰의 나강림', 273: '수희0_tngmlek0_', 274: '순수한 동거생활', 275: '순정말고 순종', 276: '순정빌런', 277: '슈퍼스타 천대리', 278: '스치면 인연 스며들면 사랑', 279: '스터디그룹', 280: '스토커의 하루', 281: '시선 끝 브로콜리', 282: '시에라', 283: '시월드가 내게 집착한다', 284: '시체기사 군터', 285: '시한부인 줄 알았어요_', 286: '신군', 287: '신의 최애캐', 288: '신이 담긴 아이', 289: '신화급 귀속 아이템을 손에 넣었다', 290: '실버 쥬얼', 291: '싸움독학', 292: '쌈빡', 293: '쓰레기는 쓰레기통에_', 294: '아가사', 295: '아마도', 296: '아마도_ 굿모닝', 297: '아빠같은 남자', 298: '아슈타르테', 299: '아이돌만 하고 싶었는데', 300: '아이즈', 301: '아인슈페너', 302: '아찔한 전남편', 303: '아침을 지나 밤으로', 304: '아카데미에 위장취업당했다', 305: '아포크리파', 306: '아홉수 우리들', 307: '악녀 18세 공략기', 308: '악당과 악당이 만나면', 309: '악마라고 불러다오', 310: '악몽의 형상', 311: '안녕_ 나의 수집', 312: '안미운 우리들', 313: '애구애구', 314: '애옹식당', 315: '애증화음', 316: '앵무살수', 317: '약빨이 신선함', 318: '약탈 신부', 319: '약한영웅', 320: '어글리후드', 321: '어느 백작 영애의 이중생활', 322: '어느날 갑자기 서울은', 323: '어떤소란', 324: '어쩌다보니 천생연분', 325: '언니_ 이번 생엔 내가 왕비야', 326: '언다잉', 327: '언덕 위의 제임스', 328: '에브리띵 이즈 파인', 329: '에이머', 330: '엑스애쉬', 331: '엔딩_ 바꿔보려합니다', 332: '여고생 드래곤', 333: '여름의 너에게', 334: '여신강림', 335: '여신님의 호랑이 공략법', 336: '여우애담', 337: '여우자매', 338: '여자를 사귀고 싶다', 339: '역대급 영지 설계사', 340: '역주행_', 341: '연놈', 342: '연애 연기대상', 343: '연애고수', 344: '연애의 기록', 345: '연애혁명', 346: '연우의 순정', 347: '열녀박씨 계약결혼뎐', 348: '영앤리치가 아니야_', 349: '영웅&마왕&악당', 350: '옆집남자 친구', 351: '오_ 친애하는 숙적', 352: '오늘의 비너스', 353: '오로지 오로라', 354: '오빠집이 비어서', 355: '오직_ 밝은 미래', 356: '온리호프', 357: '온새미로', 358: '온실 속 화초', 359: '올가미', 360: '완벽한 결혼의 정석', 361: '완벽한 부부는 없다', 362: '완벽한 파트너', 363: '왕게임', 364: '왕년엔 용사님', 365: '왕세자 입학도', 366: '외모지상주의', 367: '용두사망 소설 속의 악녀가 되었다', 368: '용사가 돌아왔다', 369: '용사참수인', 370: '용왕님의 셰프가 되었습니다', 371: '용한소녀', 372: '우리 무슨 사이야_', 373: '우리 은하', 374: '우산 없는 애', 375: '운명을 보는 회사원', 376: '웅크', 377: '원수가 나를 유혹할 때', 378: '원작은 완결난 지 한참 됐습니다만', 379: '원주민 공포만화', 380: '원하나', 381: '위닝샷_', 382: '위대한 겸상', 383: '위아더좀비', 384: '위험한 남편을 길들이는 법', 385: '윈드브레이커', 386: '윌유메리미', 387: '유사연애', 388: '유월의 소한', 389: '은둔코인', 390: '은주의 방 2_3부', 391: '은탄', 392: '이 결혼_ 새로고침', 393: '이 짝사랑은 억울하다_', 394: '이건 그냥 연애 이야기', 395: '이게 아닌데', 396: '이게 웬 떡', 397: '이계진입 리로디드', 398: '이러면 안 돼요_ 전하_', 399: '이런 미친 엔딩', 400: '이별 후 사내 결혼', 401: '이별학', 402: '이세계 용사가 지구를 구하는 이유', 403: '이십팔세기 광팬', 404: '이제야 연애', 405: '인과관계', 406: '인생영화', 407: '인섹터', 408: '인피니티', 409: '일렉시드', 410: '일타강사 백사부', 411: '입술이 예쁜 남자', 412: '입학용병', 413: '자매전쟁', 414: '자취방 신선들', 415: '작전명 순정', 416: '잔불의 기사', 417: '장미같은 소리', 418: '장씨세가 호위무사', 419: '장풍전', 420: '재벌집 막내아들', 421: '재생존경쟁', 422: '잿더미 황후', 423: '잿빛도 색이다', 424: '잿빛오름', 425: '저 그런 인재 아닙니다', 426: '저무는 해_ 시린 눈', 427: '적월의 나라', 428: '전남편의 미친개를 길들였다', 429: '전생연분', 430: '전지적 독자 시점', 431: '절대복종', 432: '제로게임', 433: '제왕_ 빛과 그림자', 434: '조선여우스캔들', 435: '존잘주의', 436: '좀간', 437: '주부 육성중', 438: '주인님을 잡아먹는 방법', 439: '주작연애', 440: '중독연구소', 441: '중매쟁이 아가 황녀님', 442: '지니오패스', 443: '지옥 키우기', 444: '지옥급식', 445: '지옥연애환담', 446: '집사_ 주세요_', 447: '집이 없어', 448: '짝사랑 마들렌', 449: '짝사랑의 마침표', 450: '찐_종합게임동아리', 451: '참교육', 452: '천년간 노려왔습니다', 453: '천마는 평범하게 살 수 없다', 454: '천마육성', 455: '천상의 주인', 456: '천재의 게임방송', 457: '천치전능', 458: '천하제일 대사형', 459: '천하제일인', 460: '천화서고 대공자', 461: '철수와 영희 이야기', 462: '첫날밤만 세 번째', 463: '청춘 블라썸', 464: '청춘계시록', 465: '청춘일지', 466: '초인의 게임', 467: '최강부캐', 468: '최강전설 강해효', 469: '최면학교', 470: '최후의 금빛아이', 471: '취사병 전설이 되다', 472: '카루나', 473: '칼끝에 입술', 474: '칼부림', 475: '칼에 취한 밤을 걷다', 476: '커플브레이커', 477: '코인 리벤지', 478: '쿠베라', 479: '쿠쿠쿠쿠', 480: '퀘스트지상주의', 481: '크림슨 하트', 482: '키미앤조이', 483: '키스 식스 센스', 484: '키스의 여왕', 485: '킬 더 드래곤', 486: '킬더킹', 487: '킬링킬러', 488: '탑코너', 489: '태권보이', 490: '퇴근 후에 만나요', 491: '튜토리얼 탑의 고인물', 492: '트롤트랩', 493: '특수청소', 494: '팀장님은 신혼이 피곤하다', 495: '파견체', 496: '파운더', 497: '판사 이한영', 498: '판타지 여동생_', 499: '팔이피플', 500: '패션쇼', 501: '팬인데 왜요', 502: '퍼니게임', 503: '평행도시', 504: '폭군 남편과 이혼하겠습니다', 505: '폭군님은 착하게 살고 싶어', 506: '폰투스 _ 극야2', 507: '푸른 밤_ 황홀의 윤무', 508: '푸쉬오프', 509: '풋내기들', 510: '프로듀스 온리원', 511: '프리드로우', 512: '플레이어', 513: '필리아로제 _ 가시왕관의 예언', 514: '필생기', 515: '하나는 적고 둘은 너무 많아', 516: '하렘에서 살아남기', 517: '하렘의 남자들', 518: '하루만 네가 되고 싶어', 519: '하루의 하루', 520: '하북팽가 막내아들', 521: '하얀 사자의 비밀 신부', 522: '한림체육관', 523: '한입만_', 524: '합격시켜주세용', 525: '합법해적 파르페', 526: '햄버거가 제일 좋아', 527: '행성인간2_ 행성의', 528: '행운을 부탁해_', 529: '행운을 빌어요_ 용사님_', 530: '헤어지면 죽음', 531: '헥토파스칼', 532: '헬스던전', 533: '헬크래프트', 534: '현실퀘스트', 535: '호랑신랑뎐', 536: '호랑이 들어와요', 537: '호랑이형님', 538: '홀리데이', 539: '홍 의관의 은밀한 비밀', 540: '홍시는 날 좋아해_', 541: '환상연가', 542: '황궁에 핀 꽃은_ 미쳤다', 543: '황제사냥', 544: '황제와의 하룻밤', 545: '회귀한 천재 헌터의 슬기로운 청소생활', 546: '후궁 스캔들', 547: '후덜덜덜 남극전자', 548: '흑막 여주가 날 새엄마로 만들려고 해', 549: '히어로 더 맥시멈', 550: '히어로 킬러', 551: '히어로메이커'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet,self).__init__()\n",
    "        self.layer0 = nn.Sequential(*list(resnet.children())[0:1])\n",
    "        self.layer1 = nn.Sequential(*list(resnet.children())[1:4])\n",
    "        self.layer2 = nn.Sequential(*list(resnet.children())[4:5])\n",
    "        self.layer3 = nn.Sequential(*list(resnet.children())[5:6])\n",
    "        #self.layer4 = nn.Sequential(*list(resnet.children())[6:7])\n",
    "        #self.layer5 = nn.Sequential(*list(resnet.children())[7:8])\n",
    "\n",
    "    def forward(self,x):\n",
    "        out_0 = self.layer0(x)\n",
    "        out_1 = self.layer1(out_0)\n",
    "        out_2 = self.layer2(out_1)\n",
    "        out_3 = self.layer3(out_2)\n",
    "        #out_4 = self.layer4(out_3)\n",
    "        #out_5 = self.layer5(out_4)\n",
    "\n",
    "        return out_0, out_1, out_2, out_3, # out_4, out_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GramMatrix(nn.Module):\n",
    "    def forward(self, input):\n",
    "        b,c,h,w = input.size()\n",
    "        F = input.view(b, c, h*w)\n",
    "        G = torch.bmm(F, F.transpose(1,2)) \n",
    "        return G\n",
    "\n",
    "class GramMSELoss(nn.Module):\n",
    "    def forward(self, input, target):\n",
    "        out = nn.MSELoss()(GramMatrix()(input), target)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = Resnet().cuda(0)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_vec(result, label_arr, last_split_data_status):\n",
    "    image_result_vec_df = pd.DataFrame({'WebToonTitle':[], 'Xmean':[], 'Ymean':[]})\n",
    "    print(len(label_arr))\n",
    "\n",
    "    divide_idx = []\n",
    "    idx = 0\n",
    "    for i in range(len(label_arr)):\n",
    "        if((i != 0) & (label_arr[i] != label_arr[i-1])):\n",
    "            divide_idx.append([idx, i])\n",
    "            idx = i\n",
    "    if last_split_data_status:\n",
    "        divide_idx.append([idx, len(label_arr)])\n",
    "\n",
    "    print(divide_idx)\n",
    "\n",
    "    for idx in divide_idx:\n",
    "        image_result_vec_df = image_result_vec_df.append({'WebToonTitle':[idx_to_class[label_arr[idx[0]]]][0],\n",
    "                                                          'Xmean':result[idx[0]:idx[1]][0].mean(),\n",
    "                                                          'Ymean':result[idx[0]:idx[1]][1].mean()},\n",
    "                                                         ignore_index=True)\n",
    "    load_image_result_vec_df = pd.read_csv('D:webtoon_vec_mean20230211.csv', encoding='UTF-8', index_col=0)\n",
    "    load_image_result_vec_df = load_image_result_vec_df.append(image_result_vec_df)\n",
    "    load_image_result_vec_df.to_csv('D:webtoon_vec_mean20230211.csv', encoding='UTF-8')\n",
    "# image_result_vec_df.to_csv('D:webtoon_vec_mean.csv', encoding='UTF-8')\n",
    "# image_result_vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_feature_extract(data):\n",
    "    total_arr = []\n",
    "\n",
    "    for idx,image in enumerate(data):\n",
    "        i = image.cuda()\n",
    "        i = i.view(-1,i.size()[0],i.size()[1],i.size()[2])\n",
    "\n",
    "        style_target = list(GramMatrix().cuda()(i) for i in resnet(i))\n",
    "\n",
    "        arr = torch.cat([style_target[0].view(-1),style_target[1].view(-1),style_target[2].view(-1),style_target[3].view(-1)],0)\n",
    "        gram = arr.cpu().data.numpy().reshape(1,-1)\n",
    "\n",
    "        total_arr.append(gram.reshape(-1))\n",
    "        \n",
    "        if idx % 100 == 0 and idx != 0:\n",
    "            print(f'{idx} images style feature extracted..[{round(idx / len(data), 2) * 100}%]')\n",
    "    print('Image style feature extraction done.')\n",
    "    return total_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data(data, idx , start_idx):\n",
    "    data_len = len(data)\n",
    "    split_image_data = []\n",
    "    split_label_data = []\n",
    "    count = 0\n",
    "    for i in range(start_idx, data_len):\n",
    "        if count != 5:\n",
    "            split_label_data.append(data[i][1])\n",
    "            split_image_data.append(data[i][0].cuda())\n",
    "        if (count == 5) & (data_len - 1 != i):\n",
    "            start_idx = i\n",
    "            break\n",
    "        if (data_len - 1 == i) | (split_label_data[i-1-start_idx] != split_label_data[i-start_idx]) & (i != start_idx):\n",
    "            print(f\"{count+1}번째 웹툰까지 누적 그림갯수는 {i}개이다\")\n",
    "            count += 1\n",
    "    print(f\"{int((idx+1)/5)}번째 split_data생성 완료\")\n",
    "    return split_image_data, split_label_data, start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:CropWebtoons541-552/까지 완료\n",
      "모든 백터값 추출 완료\n"
     ]
    }
   ],
   "source": [
    "all_file_len = 552\n",
    "for file_idx in range(int(all_file_len/30)+1):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    if int(all_file_len/30) == file_idx:\n",
    "        PATH = \"D:CropWebtoons\"+str(file_idx*30+1)+'-'+str(all_file_len)+'/'\n",
    "    else:\n",
    "        PATH = \"D:CropWebtoons\"+str(file_idx*30+1)+'-'+str((file_idx+1)*30)+'/'\n",
    "    data = datasets.ImageFolder(PATH,transform= transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "        transforms.Grayscale(num_output_channels=3)\n",
    "        ]))\n",
    "\n",
    "    class_to_idx = data.class_to_idx\n",
    "    idx_to_class = {}\n",
    "    for key, value in enumerate(class_to_idx):\n",
    "        idx_to_class[key] = value\n",
    "    print(idx_to_class)\n",
    "\n",
    "    start_idx = 0\n",
    "    titles_len = len(idx_to_class)\n",
    "    last_split_data_status = False\n",
    "\n",
    "    for idx in range(4,len(idx_to_class),5):\n",
    "        start = time.time()\n",
    "        print(f\"완료율:{((0 if idx == 4 else idx+1)/titles_len)*100}%\")\n",
    "        label_arr = []\n",
    "        split_image_data, label_arr, start_idx = get_split_data(data, idx, start_idx)\n",
    "        totar_arr = []\n",
    "        total_arr = image_feature_extract(split_image_data)\n",
    "        model = TSNE(n_components=2, init='pca',random_state=0, verbose=3, perplexity=100)\n",
    "        result = model.fit_transform(total_arr)\n",
    "        if (idx + 1) == len(idx_to_class):\n",
    "            last_split_data_status = True\n",
    "        save_vec(result, label_arr, last_split_data_status)\n",
    "        print(\"time :\", time.time() - start)\n",
    "        del split_image_data\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    clear_output(wait=True)\n",
    "    print(f\"{PATH}까지 완료\")\n",
    "print('모든 백터값 추출 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_num = 5\n",
    "copyPath = \"D:/CropWebtoons/\"\n",
    "PATH = \"D:/RandomCropWebtoons/\"\n",
    "\n",
    "for i in range(repeat_num):\n",
    "    start = time.time()\n",
    "    rand_arr = []\n",
    "    while len(rand_arr) < 5:\n",
    "        rand_num = random.randrange(552)\n",
    "        while(rand_num not in rand_arr):\n",
    "            rand_arr.append(rand_num)\n",
    "    \n",
    "    os.mkdir(PATH)\n",
    "    for i in rand_arr:\n",
    "        os.mkdir(PATH+all_file_idx_to_class[i])\n",
    "        for j in range(len(os.listdir(copyPath+all_file_idx_to_class[i]+'/'))):\n",
    "            origin_file = copyPath+all_file_idx_to_class[i]+'/'+str(j)+'.jpg'\n",
    "            copy_file = PATH+all_file_idx_to_class[i]+'/'+str(j)+'.jpg'\n",
    "            shutil.copy(origin_file, copy_file)\n",
    "        print(all_file_idx_to_class[i],\"복사 완료\")\n",
    "    \n",
    "    data = datasets.ImageFolder(PATH,transform= transforms.Compose([\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.CenterCrop(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Grayscale(num_output_channels=3)\n",
    "    ]))\n",
    "    \n",
    "    class_to_idx = data.class_to_idx\n",
    "    idx_to_class = {}\n",
    "    for key, value in enumerate(class_to_idx):\n",
    "        idx_to_class[key] = value\n",
    "    print(idx_to_class)\n",
    "    \n",
    "    start_idx = 0\n",
    "    titles_len = len(idx_to_class)\n",
    "    last_split_data_status = False\n",
    "\n",
    "    for idx in range(4,len(idx_to_class),5):\n",
    "        label_arr = []\n",
    "        split_image_data, label_arr, start_idx = get_split_data(data, idx, start_idx)\n",
    "        totar_arr = []\n",
    "        total_arr = image_feature_extract(split_image_data)\n",
    "        model = TSNE(n_components=2, init='pca',random_state=0, verbose=3, perplexity=100)\n",
    "        result = model.fit_transform(total_arr)\n",
    "        if (idx + 5) > len(idx_to_class):\n",
    "            last_split_data_status = True\n",
    "        save_vec(result, label_arr, last_split_data_status)\n",
    "        del split_image_data\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    clear_output(wait=True)\n",
    "    print(f\"{PATH}까지 완료\")\n",
    "    shutil.rmtree(PATH)\n",
    "    print(\"time :\", time.time() - start)\n",
    "print('모든 백터값 추출 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>WebToonTitle</th>\n",
       "      <th>Xmean</th>\n",
       "      <th>Ymean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AI 유하</td>\n",
       "      <td>34957.100000</td>\n",
       "      <td>104387.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>겨울특강</td>\n",
       "      <td>33205.240000</td>\n",
       "      <td>107172.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기억해줘</td>\n",
       "      <td>-78063.540000</td>\n",
       "      <td>126712.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>내일</td>\n",
       "      <td>63022.620000</td>\n",
       "      <td>59304.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>노량진 공격대</td>\n",
       "      <td>-28374.607000</td>\n",
       "      <td>107774.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0</td>\n",
       "      <td>회귀한 천재 헌터의 슬기로운 청소생활</td>\n",
       "      <td>-100460.500000</td>\n",
       "      <td>176208.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1</td>\n",
       "      <td>후궁 스캔들</td>\n",
       "      <td>-115110.718750</td>\n",
       "      <td>-78606.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>2</td>\n",
       "      <td>후덜덜덜 남극전자</td>\n",
       "      <td>-62509.250000</td>\n",
       "      <td>-39704.191406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>3</td>\n",
       "      <td>흑막 여주가 날 새엄마로 만들려고 해</td>\n",
       "      <td>-78394.632812</td>\n",
       "      <td>-35544.019531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>4</td>\n",
       "      <td>히어로 더 맥시멈</td>\n",
       "      <td>140289.625000</td>\n",
       "      <td>89200.929688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0          WebToonTitle          Xmean          Ymean\n",
       "0             0                 AI 유하   34957.100000  104387.420000\n",
       "1             1                  겨울특강   33205.240000  107172.130000\n",
       "2             2                  기억해줘  -78063.540000  126712.400000\n",
       "3             3                    내일   63022.620000   59304.660000\n",
       "4             4               노량진 공격대  -28374.607000  107774.200000\n",
       "..          ...                   ...            ...            ...\n",
       "595           0  회귀한 천재 헌터의 슬기로운 청소생활 -100460.500000  176208.562500\n",
       "596           1                후궁 스캔들 -115110.718750  -78606.601562\n",
       "597           2             후덜덜덜 남극전자  -62509.250000  -39704.191406\n",
       "598           3  흑막 여주가 날 새엄마로 만들려고 해  -78394.632812  -35544.019531\n",
       "599           4             히어로 더 맥시멈  140289.625000   89200.929688\n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vec = pd.read_csv(\"D:webtoon_vec_mean.csv\",encoding='utf-8')\n",
    "mean_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec = mean_vec.loc[52:,['WebToonTitle','Xmean','Ymean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec = pd.read_csv('D:webtoon_vec_mean.csv', encoding='ansi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec = mean_vec.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec.to_csv('D:webtoon_vec_mean.csv', encoding='ansi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(label_arr))\n",
    "label_arr[3345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = TSNE(n_components=2, init='pca',random_state=0, verbose=3, perplexity=100)\n",
    "result = model.fit_transform(total_arr)\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imscatter(x, y, image, ax=None, zoom=1, show_by_thumnail=False, title='webtoon'):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    try:\n",
    "        image = plt.imread(image)\n",
    "    except TypeError:\n",
    "        # Likely already an array...\n",
    "        pass\n",
    "    im = OffsetImage(image, zoom=zoom)\n",
    "\n",
    "    # Convert inputs to arrays with at least one dimension.\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    \n",
    "    artists = []\n",
    "    for x0, y0 in zip(x, y):\n",
    "        ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=False)\n",
    "        \n",
    "\n",
    "        if show_by_thumnail:\n",
    "            offsetbox = TextArea(title, minimumdescent=False)\n",
    "            ac = AnnotationBbox(offsetbox, (x0, y0),\n",
    "                        xybox=(20, -40),\n",
    "                        xycoords='data',\n",
    "                        boxcoords=\"offset points\")\n",
    "            artists.append(ax.add_artist(ac))\n",
    "        artists.append(ax.add_artist(ab))\n",
    "\n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()\n",
    "    return artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(0,2292):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='red')\n",
    "for i in range(2292, 3219):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='blue')\n",
    "# for i in range(3220, 4206):\n",
    "#     img_path = img_list[i]\n",
    "#     plt.scatter(result[i][0], result[i][1], c='green')\n",
    "#     imscatter(result[i,0],result[i,1], image=img_path, zoom=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(0,2292):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='red')\n",
    "# for i in range(2292, 3219):\n",
    "#     img_path = img_list[i]\n",
    "#     plt.scatter(result[i][0], result[i][1], c='blue')\n",
    "for i in range(3220, 4206):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='green')\n",
    "#     imscatter(result[i,0],result[i,1], image=img_path, zoom=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# for i in range(0,2292):\n",
    "#     img_path = img_list[i]\n",
    "#     plt.scatter(result[i][0], result[i][1], c='red')\n",
    "for i in range(2292, 3219):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='blue')\n",
    "for i in range(3220, 4206):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='green')\n",
    "#     imscatter(result[i,0],result[i,1], image=img_path, zoom=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(0,2292):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='red')\n",
    "for i in range(2292, 3219):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='blue')\n",
    "# for i in range(3220, 4206):\n",
    "#     img_path = img_list[i]\n",
    "#     plt.scatter(result[i][0], result[i][1], c='green')\n",
    "#     imscatter(result[i,0],result[i,1], image=img_path, zoom=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(result[:2292][0].mean(), result[:2292][1].mean())\n",
    "plt.scatter(result[2292:3219][0].mean(),result[2292:3219][1].mean())\n",
    "plt.scatter(result[3219:][0].mean(),result[3219:][1].mean())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_list = []\n",
    "scatter_x = result[:, 0]\n",
    "scatter_y = result[:, 1]\n",
    "group = np.array(label_arr)\n",
    "\n",
    "for g in np.unique(group):\n",
    "    i = np.where(group==g)\n",
    "    x_avg = np.mean(scatter_x[i])\n",
    "    y_avg = np.mean(scatter_y[i])\n",
    "    avg_list.append((x_avg, y_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(len(avg_list)):\n",
    "    img_path = img_list2[i]\n",
    "    imscatter(avg_list[i][0],avg_list[i][1], image=img_path,zoom=0.6, show_by_thumnail=True, title=idx_to_class[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def configInfo(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "def imgList(data, config='config.json'):\n",
    "\n",
    "    thumnail_path = configInfo(config)[\"path\"][\"thumnail\"]\n",
    "    img_list, img_list2 = [], []\n",
    "\n",
    "    for img in data.imgs:\n",
    "        img_list.append(img[0])\n",
    "\n",
    "    for img in os.listdir(thumnail_path):\n",
    "        img_list2.append(os.path.join(thumnail_path,img))\n",
    "    img_list2.sort()\n",
    "\n",
    "    return img_list, img_list2\n",
    "\n",
    "def avgList(result, label_arr):\n",
    "\n",
    "    avg_list = []\n",
    "    scatter_x = result[:, 0]\n",
    "    scatter_y = result[:, 1]\n",
    "    group = np.array(label_arr)\n",
    "\n",
    "    for g in np.unique(group):\n",
    "        i = np.where(group == g)\n",
    "        x_avg = np.mean(scatter_x[i])\n",
    "        y_avg = np.mean(scatter_y[i])\n",
    "        avg_list.append((x_avg, y_avg))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000\n",
    "\n",
    "\n",
    "def getCoord(image, height, width, std):\n",
    "\n",
    "    mid = width // 2\n",
    "    coor = []\n",
    "    final = []\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(height):\n",
    "        if image[i, mid, 0] == 255 and image[i, mid, 1] == 255 and image[i, mid, 2] == 255:\n",
    "            continue\n",
    "        if coor:\n",
    "            if abs(coor[-1] - i) > std:\n",
    "                final.append((coor[0], coor[-1]))\n",
    "                cnt += 1\n",
    "                coor = []\n",
    "            else:\n",
    "                coor.append(i)\n",
    "        else:\n",
    "            coor.append(i)\n",
    "\n",
    "        if i == height-1:\n",
    "            start, end = coor[0], coor[-1]\n",
    "            final.append((start, end))\n",
    "            cnt += 1\n",
    "\n",
    "    return cnt, final\n",
    "\n",
    "\n",
    "def Croptoon(path, save_dir, std=150):\n",
    "    hap = 0\n",
    "    i = 0\n",
    "\n",
    "    for file in glob.glob(path + '/*'):\n",
    "        try:\n",
    "            image = np.asarray(Image.open(file))\n",
    "            cnt, final = getCoord(image, image.shape[0], image.shape[1], std)\n",
    "            hap += cnt\n",
    "            for (start, end) in final:\n",
    "                cropped = image[start:end, :]\n",
    "                if cropped.shape[0] < 250:\n",
    "                    hap -= 1\n",
    "                    continue\n",
    "                cropped = Image.fromarray(cropped)\n",
    "                cropped.save(save_dir + '/' + str(i) + \".jpg\")\n",
    "                i += 1\n",
    "            print(f'{file} cropped => {cnt} images')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(f'Total {hap} images cropped')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    webtoon_path = \"D:webtoons/\"\n",
    "    cropped_path = \"D:CropWebtoons/\"\n",
    "\n",
    "    if 'cropped' not in os.listdir('D:webtoons/'):\n",
    "        os.mkdir(cropped_path)\n",
    "\n",
    "    for dir in os.listdir(webtoon_path):\n",
    "        os.makedirs(os.path.join(os.getcwd(), cropped_path, dir))\n",
    "\n",
    "    for toon in os.listdir(webtoon_path):\n",
    "        try:\n",
    "            Croptoon(webtoon_path + toon, cropped_path + toon)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "wt_info = pd.read_csv('D:webtoons코드 파일/네이버 웹툰 정보ansi.csv', encoding=\"CP949\")\n",
    "wt_name = wt_info['title']\n",
    "\n",
    "for i in range(len(wt_name)):\n",
    "    folder_title = re.sub(\"[-=+,#/\\?:^.@*\\\"※~ㆍ!』‘|\\(\\)\\[\\]`\\'…》\\”\\“\\’·]\",'_',wt_name[i])\n",
    "    path1 = 'D:webtoons/'+ folder_title +'/1'\n",
    "    try:\n",
    "        len_files = len(os.listdir(path1))\n",
    "        sum_img_height = 0\n",
    "        for j in range(1, len_files + 1):\n",
    "            img1 = Image.open(path1+'/'+str(j)+'.jpg')\n",
    "            sum_img_height = sum_img_height + (img1.size)[1]\n",
    "        sum_img = Image.new('RGB', ((img1.size)[0], sum_img_height),(255,255,255))\n",
    "        sum_paste_img_height = 0\n",
    "        for j in range(1, len_files + 1):\n",
    "            img1 = Image.open(path1+'/'+str(j)+'.jpg')\n",
    "            sum_img.paste(img1, (0, sum_paste_img_height))\n",
    "            sum_paste_img_height=sum_paste_img_height + (img1.size)[1]\n",
    "        os.mkdir('D:webtoon_sum_episode1/'+folder_title)\n",
    "        sum_img.save('D:webtoon_sum_episode1/'+folder_title+'/'+wt_name[i]+'.png', 'PNG')\n",
    "        print(wt_name[i],\"완료\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "before_path = 'D:CropWebtoons/'\n",
    "after1_path = 'D:CropWebtoons50/'\n",
    "after2_path = 'D:CropWebtoons20/'\n",
    "\n",
    "# wt_copy_list = ['연애혁명',\n",
    "#                 '외모지상주의',\n",
    "#                 '프리드로우',\n",
    "#                 '소녀의 세계',\n",
    "#                 '윌유메리미',\n",
    "#                 '쿠베라',\n",
    "#                 '호랑이형님',\n",
    "#                 '윈드브레이커',\n",
    "#                 '뷰티풀 군바리',\n",
    "#                 '연놈',\n",
    "#                 '세라는 망돌',\n",
    "#                 '하나는 적고 둘은 너무 많아',\n",
    "#                 '겨울특강',\n",
    "#                 'AI 유하',\n",
    "#                 '독거미',\n",
    "#                 '보고 있지_',\n",
    "#                 '원수가 나를 유혹할 때',\n",
    "#                 '산의 시간',\n",
    "#                 '천년간 노려왔습니다',\n",
    "#                 '노량진 공격대']\n",
    "\n",
    "\n",
    "# for dir in os.listdir(before_path):\n",
    "#     os.makedirs(os.path.join(os.getcwd(), after2_path, dir))\n",
    "\n",
    "start_i = 0\n",
    "for i in range(30,len(idx_to_class),30):\n",
    "#     f_path = 'D:CropWebtoons'+str(i-29)+'-'+str(i)\n",
    "#     os.mkdir(f_path)\n",
    "#     for j in range(start_i, i):\n",
    "#         os.mkdir(f_path+'/'+idx_to_class[j])\n",
    "#         for k in range(len(os.listdir(before_path+idx_to_class[j]+'/'))):\n",
    "#             origin_file = before_path+idx_to_class[j]+'/'+str(k)+'.jpg'\n",
    "#             copy_file = f_path+'/'+idx_to_class[j]+'/'+str(k)+'.jpg'\n",
    "#             shutil.copy(origin_file, copy_file)\n",
    "#     start_i += 30\n",
    "#     print(f_path,'완료')\n",
    "    if i+30 > len(idx_to_class):\n",
    "        start_i = int(len(idx_to_class)/30)*30\n",
    "        f_path = 'D:CropWebtoons'+str(i+1)+'-'+str(len(idx_to_class))\n",
    "        os.mkdir(f_path)\n",
    "        for j in range(start_i, len(idx_to_class)):\n",
    "            os.mkdir(f_path+'/'+idx_to_class[j])\n",
    "            for k in range(len(os.listdir(before_path+idx_to_class[j]+'/'))):\n",
    "                origin_file = before_path+idx_to_class[j]+'/'+str(k)+'.jpg'\n",
    "                copy_file = f_path+'/'+idx_to_class[j]+'/'+str(k)+'.jpg'\n",
    "                shutil.copy(origin_file, copy_file)\n",
    "        print(f_path,'완료')\n",
    "    \n",
    "\n",
    "# for title in wt_copy_list:\n",
    "#     os.mkdir(after2_path+title)\n",
    "\n",
    "# for path in os.listdir(after2_path):\n",
    "#     for i in range(len(os.listdir(before_path+path))):\n",
    "#         origin_file = before_path+path+'/'+str(i)+'.jpg'\n",
    "#         copy_file = after2_path+path+'/'+str(i)+'.jpg'\n",
    "#         shutil.copy(origin_file, copy_file)\n",
    "#     print(path,'완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('D:CropWebtoons/')[0]\n",
    "int(559/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(wt_name))\n",
    "print(wt_name[560])\n",
    "# len(os.listdir(\"D:webtoons/참교육/1/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pymysql\n",
    "\n",
    "u='four'\n",
    "pw='clover'\n",
    "h='project-db-stu.ddns.net'\n",
    "p=3307\n",
    "d='four'\n",
    "\n",
    "try:\n",
    "    pymysql.connect(user=u, password=pw, host=h, port=p, database=d)\n",
    "    print(\"DB Connetion Success:{0}\".format(h))\n",
    "except pymysql.Error as e:\n",
    "    print(\"Error conneting to MySQL Platform : {}\".format(e))\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "302779809afbf23da4daeb99e534cc5dde3b98656398965bacd60ca2c0f220c1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
