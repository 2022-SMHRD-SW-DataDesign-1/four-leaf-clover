{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils as utils\n",
    "import torch.utils.data as data\n",
    "import torchvision.models as models\n",
    "import torchvision.utils as v_utils\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "# from tsnecuda import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox, TextArea\n",
    "from matplotlib.cbook import get_sample_data\n",
    "from PIL import ImageFile\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "# import cupy as cp\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "image_size = 256\n",
    "PATH = \"D:CropWebtoons/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.ImageFolder(PATH,transform= transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "        transforms.Grayscale(num_output_channels=3)\n",
    "        ]))\n",
    "\n",
    "print(data.class_to_idx)\n",
    "\n",
    "class_to_idx = data.class_to_idx\n",
    "idx_to_class = {}\n",
    "for key, value in enumerate(class_to_idx):\n",
    "    idx_to_class[key] = value\n",
    "    \n",
    "print(idx_to_class)\n",
    "all_file_idx_to_class = idx_to_class\n",
    "# img_list = []\n",
    "# for i in data.imgs:\n",
    "#     img_list.append(i[0])\n",
    "\n",
    "#img_list2 = []\n",
    "\n",
    "#for img in os.listdir('/content/drive/My Drive/dataset/thumnail'):\n",
    "#    img_list2.append(os.path.join('/content/drive/My Drive/dataset/thumnail',img))\n",
    "#img_list2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "C:\\Users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnet,self).__init__()\n",
    "        self.layer0 = nn.Sequential(*list(resnet.children())[0:1])\n",
    "        self.layer1 = nn.Sequential(*list(resnet.children())[1:4])\n",
    "        self.layer2 = nn.Sequential(*list(resnet.children())[4:5])\n",
    "        self.layer3 = nn.Sequential(*list(resnet.children())[5:6])\n",
    "        #self.layer4 = nn.Sequential(*list(resnet.children())[6:7])\n",
    "        #self.layer5 = nn.Sequential(*list(resnet.children())[7:8])\n",
    "\n",
    "    def forward(self,x):\n",
    "        out_0 = self.layer0(x)\n",
    "        out_1 = self.layer1(out_0)\n",
    "        out_2 = self.layer2(out_1)\n",
    "        out_3 = self.layer3(out_2)\n",
    "        #out_4 = self.layer4(out_3)\n",
    "        #out_5 = self.layer5(out_4)\n",
    "\n",
    "        return out_0, out_1, out_2, out_3, # out_4, out_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GramMatrix(nn.Module):\n",
    "    def forward(self, input):\n",
    "        b,c,h,w = input.size()\n",
    "        F = input.view(b, c, h*w)\n",
    "        G = torch.bmm(F, F.transpose(1,2)) \n",
    "        return G\n",
    "\n",
    "class GramMSELoss(nn.Module):\n",
    "    def forward(self, input, target):\n",
    "        out = nn.MSELoss()(GramMatrix()(input), target)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = Resnet().cuda(0)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_vec(result, label_arr, last_split_data_status):\n",
    "    image_result_vec_df = pd.DataFrame({'WebToonTitle':[], 'Xmean':[], 'Ymean':[]})\n",
    "    print(len(label_arr))\n",
    "\n",
    "    divide_idx = []\n",
    "    idx = 0\n",
    "    for i in range(len(label_arr)):\n",
    "        if((i != 0) & (label_arr[i] != label_arr[i-1])):\n",
    "            divide_idx.append([idx, i])\n",
    "            idx = i\n",
    "    if last_split_data_status:\n",
    "        divide_idx.append([idx, len(label_arr)])\n",
    "\n",
    "    print(divide_idx)\n",
    "\n",
    "    for idx in divide_idx:\n",
    "        image_result_vec_df = image_result_vec_df.append({'WebToonTitle':[idx_to_class[label_arr[idx[0]]]][0],\n",
    "                                                          'Xmean':result[idx[0]:idx[1]][0].mean(),\n",
    "                                                          'Ymean':result[idx[0]:idx[1]][1].mean()},\n",
    "                                                         ignore_index=True)\n",
    "    load_image_result_vec_df = pd.read_csv('D:webtoon_vec_mean.csv', encoding='UTF-8', index_col=0)\n",
    "    load_image_result_vec_df = load_image_result_vec_df.append(image_result_vec_df)\n",
    "    load_image_result_vec_df.to_csv('D:webtoon_vec_mean.csv', encoding='UTF-8')\n",
    "# image_result_vec_df.to_csv('D:webtoon_vec_mean.csv', encoding='UTF-8')\n",
    "# image_result_vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_feature_extract(data):\n",
    "    total_arr = []\n",
    "\n",
    "    for idx,image in enumerate(data):\n",
    "        i = image.cuda()\n",
    "        i = i.view(-1,i.size()[0],i.size()[1],i.size()[2])\n",
    "\n",
    "        style_target = list(GramMatrix().cuda()(i) for i in resnet(i))\n",
    "\n",
    "        arr = torch.cat([style_target[0].view(-1),style_target[1].view(-1),style_target[2].view(-1),style_target[3].view(-1)],0)\n",
    "        gram = arr.cpu().data.numpy().reshape(1,-1)\n",
    "\n",
    "        total_arr.append(gram.reshape(-1))\n",
    "        \n",
    "        if idx % 100 == 0 and idx != 0:\n",
    "            print(f'{idx} images style feature extracted..[{round(idx / len(data), 2) * 100}%]')\n",
    "    print('Image style feature extraction done.')\n",
    "    return total_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data(data, idx , start_idx):\n",
    "    data_len = len(data)\n",
    "    split_image_data = []\n",
    "    split_label_data = []\n",
    "    count = 0\n",
    "    for i in range(start_idx, data_len):\n",
    "        if count != 5:\n",
    "            split_label_data.append(data[i][1])\n",
    "            split_image_data.append(data[i][0].cuda())\n",
    "        if (count == 5) & (data_len - 1 != i):\n",
    "            start_idx = i\n",
    "            break\n",
    "        if (data_len - 1 == i) | (split_label_data[i-1-start_idx] != split_label_data[i-start_idx]) & (i != start_idx):\n",
    "            print(f\"{count+1}번째 웹툰까지 누적 그림갯수는 {i}개이다\")\n",
    "            count += 1\n",
    "    print(f\"{int((idx+1)/5)}번째 split_data생성 완료\")\n",
    "    return split_image_data, split_label_data, start_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:CropWebtoons541-552/까지 완료\n",
      "모든 백터값 추출 완료\n"
     ]
    }
   ],
   "source": [
    "all_file_len = 552\n",
    "for file_idx in range(int(all_file_len/30)+1):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    if int(all_file_len/30) == file_idx:\n",
    "        PATH = \"D:CropWebtoons\"+str(file_idx*30+1)+'-'+str(all_file_len)+'/'\n",
    "    else:\n",
    "        PATH = \"D:CropWebtoons\"+str(file_idx*30+1)+'-'+str((file_idx+1)*30)+'/'\n",
    "    data = datasets.ImageFolder(PATH,transform= transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "        transforms.Grayscale(num_output_channels=3)\n",
    "        ]))\n",
    "\n",
    "    class_to_idx = data.class_to_idx\n",
    "    idx_to_class = {}\n",
    "    for key, value in enumerate(class_to_idx):\n",
    "        idx_to_class[key] = value\n",
    "    print(idx_to_class)\n",
    "\n",
    "    start_idx = 0\n",
    "    titles_len = len(idx_to_class)\n",
    "    last_split_data_status = False\n",
    "\n",
    "    for idx in range(4,len(idx_to_class),5):\n",
    "        start = time.time()\n",
    "        print(f\"완료율:{((0 if idx == 4 else idx+1)/titles_len)*100}%\")\n",
    "        label_arr = []\n",
    "        split_image_data, label_arr, start_idx = get_split_data(data, idx, start_idx)\n",
    "        totar_arr = []\n",
    "        total_arr = image_feature_extract(split_image_data)\n",
    "        model = TSNE(n_components=2, init='pca',random_state=0, verbose=3, perplexity=100)\n",
    "        result = model.fit_transform(total_arr)\n",
    "        if (idx + 1) == len(idx_to_class):\n",
    "            last_split_data_status = True\n",
    "        save_vec(result, label_arr, last_split_data_status)\n",
    "        print(\"time :\", time.time() - start)\n",
    "        del split_image_data\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "    clear_output(wait=True)\n",
    "    print(f\"{PATH}까지 완료\")\n",
    "print('모든 백터값 추출 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>WebToonTitle</th>\n",
       "      <th>Xmean</th>\n",
       "      <th>Ymean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AI 유하</td>\n",
       "      <td>34957.100000</td>\n",
       "      <td>104387.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>겨울특강</td>\n",
       "      <td>33205.240000</td>\n",
       "      <td>107172.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>기억해줘</td>\n",
       "      <td>-78063.540000</td>\n",
       "      <td>126712.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>내일</td>\n",
       "      <td>63022.620000</td>\n",
       "      <td>59304.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>노량진 공격대</td>\n",
       "      <td>-28374.607000</td>\n",
       "      <td>107774.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0</td>\n",
       "      <td>회귀한 천재 헌터의 슬기로운 청소생활</td>\n",
       "      <td>-100460.500000</td>\n",
       "      <td>176208.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1</td>\n",
       "      <td>후궁 스캔들</td>\n",
       "      <td>-115110.718750</td>\n",
       "      <td>-78606.601562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>2</td>\n",
       "      <td>후덜덜덜 남극전자</td>\n",
       "      <td>-62509.250000</td>\n",
       "      <td>-39704.191406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>3</td>\n",
       "      <td>흑막 여주가 날 새엄마로 만들려고 해</td>\n",
       "      <td>-78394.632812</td>\n",
       "      <td>-35544.019531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>4</td>\n",
       "      <td>히어로 더 맥시멈</td>\n",
       "      <td>140289.625000</td>\n",
       "      <td>89200.929688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0          WebToonTitle          Xmean          Ymean\n",
       "0             0                 AI 유하   34957.100000  104387.420000\n",
       "1             1                  겨울특강   33205.240000  107172.130000\n",
       "2             2                  기억해줘  -78063.540000  126712.400000\n",
       "3             3                    내일   63022.620000   59304.660000\n",
       "4             4               노량진 공격대  -28374.607000  107774.200000\n",
       "..          ...                   ...            ...            ...\n",
       "595           0  회귀한 천재 헌터의 슬기로운 청소생활 -100460.500000  176208.562500\n",
       "596           1                후궁 스캔들 -115110.718750  -78606.601562\n",
       "597           2             후덜덜덜 남극전자  -62509.250000  -39704.191406\n",
       "598           3  흑막 여주가 날 새엄마로 만들려고 해  -78394.632812  -35544.019531\n",
       "599           4             히어로 더 맥시멈  140289.625000   89200.929688\n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vec = pd.read_csv(\"D:webtoon_vec_mean.csv\",encoding='utf-8')\n",
    "mean_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec = mean_vec.loc[52:,['WebToonTitle','Xmean','Ymean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec = pd.read_csv('D:webtoon_vec_mean.csv', encoding='ansi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec = mean_vec.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vec.to_csv('D:webtoon_vec_mean.csv', encoding='ansi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_file_idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(label_arr))\n",
    "label_arr[3345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model = TSNE(n_components=2, init='pca',random_state=0, verbose=3, perplexity=100)\n",
    "result = model.fit_transform(total_arr)\n",
    "print(\"time :\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imscatter(x, y, image, ax=None, zoom=1, show_by_thumnail=False, title='webtoon'):\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    try:\n",
    "        image = plt.imread(image)\n",
    "    except TypeError:\n",
    "        # Likely already an array...\n",
    "        pass\n",
    "    im = OffsetImage(image, zoom=zoom)\n",
    "\n",
    "    # Convert inputs to arrays with at least one dimension.\n",
    "    x, y = np.atleast_1d(x, y)\n",
    "    \n",
    "    artists = []\n",
    "    for x0, y0 in zip(x, y):\n",
    "        ab = AnnotationBbox(im, (x0, y0), xycoords='data', frameon=False)\n",
    "        \n",
    "\n",
    "        if show_by_thumnail:\n",
    "            offsetbox = TextArea(title, minimumdescent=False)\n",
    "            ac = AnnotationBbox(offsetbox, (x0, y0),\n",
    "                        xybox=(20, -40),\n",
    "                        xycoords='data',\n",
    "                        boxcoords=\"offset points\")\n",
    "            artists.append(ax.add_artist(ac))\n",
    "        artists.append(ax.add_artist(ab))\n",
    "\n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()\n",
    "    return artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(0,2292):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='red')\n",
    "for i in range(2292, 3219):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='blue')\n",
    "# for i in range(3220, 4206):\n",
    "#     img_path = img_list[i]\n",
    "#     plt.scatter(result[i][0], result[i][1], c='green')\n",
    "#     imscatter(result[i,0],result[i,1], image=img_path, zoom=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(0,2292):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='red')\n",
    "# for i in range(2292, 3219):\n",
    "#     img_path = img_list[i]\n",
    "#     plt.scatter(result[i][0], result[i][1], c='blue')\n",
    "for i in range(3220, 4206):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='green')\n",
    "#     imscatter(result[i,0],result[i,1], image=img_path, zoom=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "# for i in range(0,2292):\n",
    "#     img_path = img_list[i]\n",
    "#     plt.scatter(result[i][0], result[i][1], c='red')\n",
    "for i in range(2292, 3219):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='blue')\n",
    "for i in range(3220, 4206):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='green')\n",
    "#     imscatter(result[i,0],result[i,1], image=img_path, zoom=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(0,2292):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='red')\n",
    "for i in range(2292, 3219):\n",
    "    img_path = img_list[i]\n",
    "    plt.scatter(result[i][0], result[i][1], c='blue')\n",
    "# for i in range(3220, 4206):\n",
    "#     img_path = img_list[i]\n",
    "#     plt.scatter(result[i][0], result[i][1], c='green')\n",
    "#     imscatter(result[i,0],result[i,1], image=img_path, zoom=0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(result[:2292][0].mean(), result[:2292][1].mean())\n",
    "plt.scatter(result[2292:3219][0].mean(),result[2292:3219][1].mean())\n",
    "plt.scatter(result[3219:][0].mean(),result[3219:][1].mean())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_list = []\n",
    "scatter_x = result[:, 0]\n",
    "scatter_y = result[:, 1]\n",
    "group = np.array(label_arr)\n",
    "\n",
    "for g in np.unique(group):\n",
    "    i = np.where(group==g)\n",
    "    x_avg = np.mean(scatter_x[i])\n",
    "    y_avg = np.mean(scatter_y[i])\n",
    "    avg_list.append((x_avg, y_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 12))\n",
    "\n",
    "for i in range(len(avg_list)):\n",
    "    img_path = img_list2[i]\n",
    "    imscatter(avg_list[i][0],avg_list[i][1], image=img_path,zoom=0.6, show_by_thumnail=True, title=idx_to_class[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def configInfo(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        config = json.load(f)\n",
    "    return config\n",
    "\n",
    "def imgList(data, config='config.json'):\n",
    "\n",
    "    thumnail_path = configInfo(config)[\"path\"][\"thumnail\"]\n",
    "    img_list, img_list2 = [], []\n",
    "\n",
    "    for img in data.imgs:\n",
    "        img_list.append(img[0])\n",
    "\n",
    "    for img in os.listdir(thumnail_path):\n",
    "        img_list2.append(os.path.join(thumnail_path,img))\n",
    "    img_list2.sort()\n",
    "\n",
    "    return img_list, img_list2\n",
    "\n",
    "def avgList(result, label_arr):\n",
    "\n",
    "    avg_list = []\n",
    "    scatter_x = result[:, 0]\n",
    "    scatter_y = result[:, 1]\n",
    "    group = np.array(label_arr)\n",
    "\n",
    "    for g in np.unique(group):\n",
    "        i = np.where(group == g)\n",
    "        x_avg = np.mean(scatter_x[i])\n",
    "        y_avg = np.mean(scatter_y[i])\n",
    "        avg_list.append((x_avg, y_avg))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000\n",
    "\n",
    "\n",
    "def getCoord(image, height, width, std):\n",
    "\n",
    "    mid = width // 2\n",
    "    coor = []\n",
    "    final = []\n",
    "    cnt = 0\n",
    "\n",
    "    for i in range(height):\n",
    "        if image[i, mid, 0] == 255 and image[i, mid, 1] == 255 and image[i, mid, 2] == 255:\n",
    "            continue\n",
    "        if coor:\n",
    "            if abs(coor[-1] - i) > std:\n",
    "                final.append((coor[0], coor[-1]))\n",
    "                cnt += 1\n",
    "                coor = []\n",
    "            else:\n",
    "                coor.append(i)\n",
    "        else:\n",
    "            coor.append(i)\n",
    "\n",
    "        if i == height-1:\n",
    "            start, end = coor[0], coor[-1]\n",
    "            final.append((start, end))\n",
    "            cnt += 1\n",
    "\n",
    "    return cnt, final\n",
    "\n",
    "\n",
    "def Croptoon(path, save_dir, std=150):\n",
    "    hap = 0\n",
    "    i = 0\n",
    "\n",
    "    for file in glob.glob(path + '/*'):\n",
    "        try:\n",
    "            image = np.asarray(Image.open(file))\n",
    "            cnt, final = getCoord(image, image.shape[0], image.shape[1], std)\n",
    "            hap += cnt\n",
    "            for (start, end) in final:\n",
    "                cropped = image[start:end, :]\n",
    "                if cropped.shape[0] < 250:\n",
    "                    hap -= 1\n",
    "                    continue\n",
    "                cropped = Image.fromarray(cropped)\n",
    "                cropped.save(save_dir + '/' + str(i) + \".jpg\")\n",
    "                i += 1\n",
    "            print(f'{file} cropped => {cnt} images')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(f'Total {hap} images cropped')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    webtoon_path = \"D:webtoons/\"\n",
    "    cropped_path = \"D:CropWebtoons/\"\n",
    "\n",
    "    if 'cropped' not in os.listdir('D:webtoons/'):\n",
    "        os.mkdir(cropped_path)\n",
    "\n",
    "    for dir in os.listdir(webtoon_path):\n",
    "        os.makedirs(os.path.join(os.getcwd(), cropped_path, dir))\n",
    "\n",
    "    for toon in os.listdir(webtoon_path):\n",
    "        try:\n",
    "            Croptoon(webtoon_path + toon, cropped_path + toon)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "wt_info = pd.read_csv('D:webtoons코드 파일/네이버 웹툰 정보ansi.csv', encoding=\"CP949\")\n",
    "wt_name = wt_info['title']\n",
    "\n",
    "for i in range(len(wt_name)):\n",
    "    folder_title = re.sub(\"[-=+,#/\\?:^.@*\\\"※~ㆍ!』‘|\\(\\)\\[\\]`\\'…》\\”\\“\\’·]\",'_',wt_name[i])\n",
    "    path1 = 'D:webtoons/'+ folder_title +'/1'\n",
    "    try:\n",
    "        len_files = len(os.listdir(path1))\n",
    "        sum_img_height = 0\n",
    "        for j in range(1, len_files + 1):\n",
    "            img1 = Image.open(path1+'/'+str(j)+'.jpg')\n",
    "            sum_img_height = sum_img_height + (img1.size)[1]\n",
    "        sum_img = Image.new('RGB', ((img1.size)[0], sum_img_height),(255,255,255))\n",
    "        sum_paste_img_height = 0\n",
    "        for j in range(1, len_files + 1):\n",
    "            img1 = Image.open(path1+'/'+str(j)+'.jpg')\n",
    "            sum_img.paste(img1, (0, sum_paste_img_height))\n",
    "            sum_paste_img_height=sum_paste_img_height + (img1.size)[1]\n",
    "        os.mkdir('D:webtoon_sum_episode1/'+folder_title)\n",
    "        sum_img.save('D:webtoon_sum_episode1/'+folder_title+'/'+wt_name[i]+'.png', 'PNG')\n",
    "        print(wt_name[i],\"완료\")\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "before_path = 'D:CropWebtoons/'\n",
    "after1_path = 'D:CropWebtoons50/'\n",
    "after2_path = 'D:CropWebtoons20/'\n",
    "\n",
    "# wt_copy_list = ['연애혁명',\n",
    "#                 '외모지상주의',\n",
    "#                 '프리드로우',\n",
    "#                 '소녀의 세계',\n",
    "#                 '윌유메리미',\n",
    "#                 '쿠베라',\n",
    "#                 '호랑이형님',\n",
    "#                 '윈드브레이커',\n",
    "#                 '뷰티풀 군바리',\n",
    "#                 '연놈',\n",
    "#                 '세라는 망돌',\n",
    "#                 '하나는 적고 둘은 너무 많아',\n",
    "#                 '겨울특강',\n",
    "#                 'AI 유하',\n",
    "#                 '독거미',\n",
    "#                 '보고 있지_',\n",
    "#                 '원수가 나를 유혹할 때',\n",
    "#                 '산의 시간',\n",
    "#                 '천년간 노려왔습니다',\n",
    "#                 '노량진 공격대']\n",
    "\n",
    "\n",
    "# for dir in os.listdir(before_path):\n",
    "#     os.makedirs(os.path.join(os.getcwd(), after2_path, dir))\n",
    "\n",
    "start_i = 0\n",
    "for i in range(30,len(idx_to_class),30):\n",
    "#     f_path = 'D:CropWebtoons'+str(i-29)+'-'+str(i)\n",
    "#     os.mkdir(f_path)\n",
    "#     for j in range(start_i, i):\n",
    "#         os.mkdir(f_path+'/'+idx_to_class[j])\n",
    "#         for k in range(len(os.listdir(before_path+idx_to_class[j]+'/'))):\n",
    "#             origin_file = before_path+idx_to_class[j]+'/'+str(k)+'.jpg'\n",
    "#             copy_file = f_path+'/'+idx_to_class[j]+'/'+str(k)+'.jpg'\n",
    "#             shutil.copy(origin_file, copy_file)\n",
    "#     start_i += 30\n",
    "#     print(f_path,'완료')\n",
    "    if i+30 > len(idx_to_class):\n",
    "        start_i = int(len(idx_to_class)/30)*30\n",
    "        f_path = 'D:CropWebtoons'+str(i+1)+'-'+str(len(idx_to_class))\n",
    "        os.mkdir(f_path)\n",
    "        for j in range(start_i, len(idx_to_class)):\n",
    "            os.mkdir(f_path+'/'+idx_to_class[j])\n",
    "            for k in range(len(os.listdir(before_path+idx_to_class[j]+'/'))):\n",
    "                origin_file = before_path+idx_to_class[j]+'/'+str(k)+'.jpg'\n",
    "                copy_file = f_path+'/'+idx_to_class[j]+'/'+str(k)+'.jpg'\n",
    "                shutil.copy(origin_file, copy_file)\n",
    "        print(f_path,'완료')\n",
    "    \n",
    "\n",
    "# for title in wt_copy_list:\n",
    "#     os.mkdir(after2_path+title)\n",
    "\n",
    "# for path in os.listdir(after2_path):\n",
    "#     for i in range(len(os.listdir(before_path+path))):\n",
    "#         origin_file = before_path+path+'/'+str(i)+'.jpg'\n",
    "#         copy_file = after2_path+path+'/'+str(i)+'.jpg'\n",
    "#         shutil.copy(origin_file, copy_file)\n",
    "#     print(path,'완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('D:CropWebtoons/')[0]\n",
    "int(559/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(wt_name))\n",
    "print(wt_name[560])\n",
    "# len(os.listdir(\"D:webtoons/참교육/1/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pymysql\n",
    "\n",
    "u='four'\n",
    "pw='clover'\n",
    "h='project-db-stu.ddns.net'\n",
    "p=3307\n",
    "d='four'\n",
    "\n",
    "try:\n",
    "    pymysql.connect(user=u, password=pw, host=h, port=p, database=d)\n",
    "    print(\"DB Connetion Success:{0}\".format(h))\n",
    "except pymysql.Error as e:\n",
    "    print(\"Error conneting to MySQL Platform : {}\".format(e))\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
