{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b8a163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab733b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6c7f7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ko-sentence-transformers\n",
      "  Downloading ko_sentence_transformers-0.3.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [6 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 36, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\smhrd\\AppData\\Local\\Temp\\pip-install-8zj148vf\\ko-sentence-transformers_28e6ce45e4a74361a06b887bba2cd3d7\\setup.py\", line 6, in <module>\n",
      "      long_description = f.read()\n",
      "  UnicodeDecodeError: 'cp949' codec can't decode byte 0xec in position 30: illegal multibyte sequence\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install ko-sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8f56774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ---------------------------------------- 86.0/86.0 kB 4.7 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 11.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from sentence_transformers) (4.64.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from sentence_transformers) (0.14.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from sentence_transformers) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from sentence_transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from sentence_transformers) (1.7.3)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 10.6 MB/s eta 0:00:00\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 10.2 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
      "     ------------------------------------- 190.3/190.3 kB 11.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (22.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.11.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\smhrd\\appdata\\roaming\\python\\python37\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: requests in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.5)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.10.31-cp37-cp37m-win_amd64.whl (268 kB)\n",
      "     ------------------------------------- 268.0/268.0 kB 16.1 MB/s eta 0:00:00\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp37-cp37m-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 11.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from nltk->sentence_transformers) (1.1.1)\n",
      "Requirement already satisfied: click in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from torchvision->sentence_transformers) (9.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence_transformers) (3.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\smhrd\\anaconda3\\envs\\opencv3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.13)\n",
      "Building wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py): started\n",
      "  Building wheel for sentence_transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=b8f21324dc9716ab7a18d4edb349d800da03a2bd59434c16ec1c770f2df16ad1\n",
      "  Stored in directory: c:\\users\\smhrd\\appdata\\local\\pip\\cache\\wheels\\83\\71\\2b\\40d17d21937fed496fb99145227eca8f20b4891240ff60c86f\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, regex, huggingface-hub, transformers, nltk, sentence_transformers\n",
      "Successfully installed huggingface-hub-0.12.0 nltk-3.8.1 regex-2022.10.31 sentence_transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.26.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb66fa13",
   "metadata": {},
   "source": [
    "### Sbert 사용 하는데 순서\n",
    "\n",
    "3. 명사 단위 토큰화해서 한번 ㄱ\n",
    "\n",
    "후보 모델\n",
    "\n",
    "paraphrase-multilingual-mpnet-base-v2\n",
    "무난\n",
    "\n",
    "paraphrase-multilingual-MiniLM-L12-v2\n",
    "==> 임베딩 단어 vector값 너무 멀어\n",
    "\n",
    "distiluse-base-multilingual-cased-v1\n",
    "===> 단어 단위 일치도가 유사도 벡터값 의미 x?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd8a927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../시놉시스요약ansi.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5f061620",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../웹툰최종데이터.csv', encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2ef0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paraphrase-multilingual-mpnet-base-v2\n",
    "# jhgan/ko-sbert-nli \n",
    "# jhgan/ko-sbert-sts\n",
    "# paraphrase-multilingual-MiniLM-L12-v2\n",
    "model = SentenceTransformer(\"jhgan/ko-sbert-nli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9767e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings = model.encode(data['synopsis'], convert_to_tensor=True)\n",
    "embeddings2 = model.encode(test, convert_to_tensor=True)\n",
    "# embeddings2 = model.encode(data['synopsis'],\n",
    "cosine_scores = util.pytorch_cos_sim(embeddings, embeddings)\n",
    "cosine_scores = cosine_scores.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "948872b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "입력 시놉시스 : 평범한 뱃사공으로 살고 있는 주인공. 하지만 그의 정체는 전설적인 검법의 후계자다. 이제 진시황이 남긴 비서를 향한 살수행이 시작된다.\n",
      "\n",
      "Top 5 젤 비슷한 시놉시스:\n",
      "장씨세가 호위무사 ::  은둔 고수. 호위 무사 되다. 무협 시대극 tensor(0.6400)\n",
      "\n",
      "\n",
      "천화서고 대공자 ::  넉넉한 풍채가 매력적인 무림맹주 후공은 어느 날 느닷없이 웬 비루먹을 청년의 몸에 들어오게 된다.청년의 이름은 범항.강호 3대 서고인  ‘천화서고’의 대공자이자답이 없는 자살희망자.후공은 환혼의 원인을 파악하기 위해범항의 몸을 단련하기 시작하고과거와는 180도 달라진 천화서고 대공자의 움직임에온 강호가 주목하기 시작하는데… tensor(0.6340)\n",
      "\n",
      "\n",
      "무림서부 ::  황제가 무공을 통한 철혈정치로 제국을 천년동안 유지함에 따라, 오로지 황군 무공만이 힘이요 법도로 살아남고, 고전 무공들은 스러지고 만다. 이런 세계에 환생한 무협지 마니아, 주인공 장건. 과연 그는 동경하던 고전 무공을 되살릴 수 있을까. 서부 대륙 개척지에서 벌어지는 정통 무협의 정수! tensor(0.6229)\n",
      "\n",
      "\n",
      "사신 ::  형의 복수를 위해 살천문의 무사 황정을 죽인 소년 종리추.살천문의 추격을 피하기 위해 살혼부의 살수 적지인살에게몸을 의탁하게 되면서 십망(十忘)이라는 거대한 소용돌이에 휩쓸린다.십망의 그늘에서 벗어나기 위해선 전설의 경지인 사무령이 되는 수밖에 없다!종리추는 과연 사무령이 되어정파 무림이 만들어놓은 숨막히는 규율 속에서 자유를 찾을 수 있을까? tensor(0.5986)\n",
      "\n",
      "\n",
      "악당과 악당이 만나면 ::  귀족들을 상대로 악명을 떨치던 제국 뒷세계 조직의 보스. 어느 날 황제로부터 대공을 암살해 달라는 의뢰를 받게 된다. 조직원들과 평범하게 살고 싶었던 보스는 의뢰를 수락하고 대공성에 잠입해 암살 시도하는데…. 하지만 어째서인지 죽지 않아? 한순간에 사랑을 속삭이는 대공에게서 보스는 무사히 탈출할 수 있을까? tensor(0.5970)\n",
      "\n",
      "\n",
      "망나니 소교주로 환생했다 ::  무림의 정쟁에 휘말려 독살당한 고금 제일의 기재, 양자각.분명 죽은 줄로 알았으나 정신을 차리게 되고, 자신이 다른 사람의 몸에 들어와 있다는 것을 알게 된다.알고 보니 자신이 있는 곳은 마교, 익힌 무공은 천마신공,이 몸의 주인은 여색을 탐하고 악귀보다 더한 짓을 하는 망나니 소교주?왜 하필이면 마교에다 이 사람인가!? tensor(0.5949)\n",
      "\n",
      "\n",
      "일타강사 백사부 ::  혈교 최고의 무공 교관, 시골 무관의 사부로 환생하다. 그리고 정파 무림의 일타강사로!이름하여 백 사부.그가 이제 전 무림을 참교육한다! tensor(0.5897)\n",
      "\n",
      "\n",
      "행운을 빌어요, 용사님! ::  전생에 무찌른 마왕이 현생의 직장 상사?!마왕을 무찌른 용사의 기억을 가지고 다시 태어난 평범한 직장인 백영웅!용사의 기억이 도움이 된 건 어릴 적 웹소설을 썼을 때뿐! 영웅은 현실에서 쓸모없는 전생의 기억을 아쉬워하며 가까스로 대기업인 대룡 ENT의 대표 이사 비서실에 취직한다. 그런데 처음 만난 대표 이사 도연화에게 전생에서 경험한 적 있는 긴장감과 떨림을 느끼는데…? 이건 마치, 아주 강한 마수를 마주했을 때와 같아…!!전생 마왕, 대표 이사와 전생 용사, 말단 비서의 지독하게 얽힌 로맨스! tensor(0.5884)\n",
      "\n",
      "\n",
      "더 해머 ::  마왕군 7군단장의 머리통을 최후의 일격으로 깨버린 뒤, 죽을 위기에 처한 '타이니'. 인류의 멸망을 막을 수 없는 절망적인 상황에서 유일하게 숨이 붙어있던 전우, '검제'는 가보의 힘을 이용해 타이니를 회귀시킨다.대륙 최고의 기사에서 빈민가 고아로 돌아와버린 타이니는 전생엔 없던 새로운 힘을 얻으며 강한 잠재력을 갖게 된다.이번 생은 과연, 인류의 멸망을 막을 수 있을까? tensor(0.5814)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_k = 10\n",
    "jj=7\n",
    "#We use np.argpartition, to only partially sort the top_k results\n",
    "top_results = np.argpartition(-cosine_scores[jj], range(top_k))[0:top_k]\n",
    "# 제일 높은 얘의 index 구하는거임. \n",
    "\n",
    "print(\"\\n\\n======================\\n\\n\")\n",
    "print(\"입력 시놉시스 :\", data['synopsis'][jj])\n",
    "print(\"\\nTop 5 젤 비슷한 시놉시스:\")\n",
    "\n",
    "k = 0\n",
    "for idx in top_results[0:top_k]:\n",
    "    if k ==0 :\n",
    "        k+=1\n",
    "        continue\n",
    "    print(data['title'][int(idx)]+\" :: \",data['synopsis'][int(idx)].strip(),  cosine_scores[jj][int(idx)])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
